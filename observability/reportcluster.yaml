# A reporting cluster is meant to include absolutely no user code, but rather
# be used solely to aggregate, explore, and alert on your telemetry. It is
# responsible for actually parsing and interfacing with the data emitted by
# your application clusters.
# Since there's no non-monitoring code, everything will live in the monitoring
# namespace.
---
apiVersion: v1
kind: Namespace
metadata:
  name: CLUSTER-monitoring
# First off, we'll deploy a prometheus and thanos deployment in the same way as
# we did in the app cluster -- after all, we want to monitoring everything in
# the reporting cluster as well! Note that the configuration is exactly the
# same here until we get to the rules config.
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: prometheus
  namespace: CLUSTER-monitoring
spec:
  replicas: 2
  selector:
    matchLabels:
      name: prometheus
  template:
    metadata:
      labels:
        name: prometheus
      annotations:
        prometheus.io/scrape: 'true'
        prometheus.io/port: '9090'
    spec:
      containers:
        - name: prometheus
          image: prom/prometheus:v2.27.1
          imagePullPolicy: IfNotPresent
          args:
            - '--config.file=/etc/prometheus-shared/prometheus.yaml'
            - '--storage.tsdb.path=/prometheus/'
            - '--web.enable-lifecycle'
            - '--storage.tsdb.no-lockfile'
            - '--storage.tsdb.min-block-duration=10m'
            - '--storage.tsdb.max-block-duration=10m'
            - '--storage.tsdb.retention.time=1h'
          ports:
            - name: prometheus-api
              containerPort: 9090
          volumeMounts:
            - name: prometheus-config-shared
              mountPath: /etc/prometheus-shared/
            - name: prometheus-rules
              mountPath: /etc/prometheus/rules
            - name: prometheus-storage
              mountPath: /prometheus/
        - name: thanos
          image: thanosio/thanos:v0.21.1
          args:
            - 'sidecar'
            - '--log.level=info'
            - '--tsdb.path=/prometheus/'
            - '--prometheus.url=http://127.0.0.1:9090'
            - '--objstore.config={type: GCS, config: {bucket: kjames-prometheus-longterm}}'
            - '--reloader.config-file=/etc/prometheus/prometheus.yaml.tmpl'
            - '--reloader.config-envsubst-file=/etc/prometheus-shared/prometheus.yaml'
            - '--reloader.rule-dir=/etc/prometheus/rules/'
          env:
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: POD_NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            - name: GOOGLE_APPLICATION_CREDENTIALS
              value: /etc/secret/adc.json
          ports:
            - name: thanos-http
              containerPort: 10902
            - name: prometheus-api
              containerPort: 10901
          livenessProbe:
            httpGet:
              port: 10902
              path: /-/healthy
          readinessProbe:
            httpGet:
              port: 10902
              path: /-/ready
          volumeMounts:
            - name: prometheus-config
              mountPath: /etc/prometheus
            - name: prometheus-config-shared
              mountPath: /etc/prometheus-shared/
            - name: prometheus-rules
              mountPath: /etc/prometheus/rules
            - name: prometheus-storage
              mountPath: /prometheus/
            - name: thanos-gcs-creds
              mountPath: /etc/secret
              readOnly: false
      volumes:
        - name: prometheus-config
          configMap:
            defaultMode: 420
            name: prometheus-config
        - name: prometheus-config-shared
          emptyDir: {}
        - name: prometheus-rules
          configMap:
            name: prometheus-rules
        - name: prometheus-storage
          emptyDir: {}
        - name: thanos-gcs-creds
          secret:
            secretName: thanos-gcs-creds
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-config
  namespace: CLUSTER-monitoring
data:
  prometheus.yaml.tmpl: |-
    global:
      scrape_interval: 60s
      evaluation_interval: 5s
      external_labels:
        cluster: $(POD_NAMESPACE)
        replica: $(POD_NAME)

    rule_files:
      - /etc/prometheus/rules/*.yaml

    alerting:
      alert_relabel_configs:
      - regex: replica
        action: labeldrop

      alertmanagers:
      - scheme: http
        static_configs:
        - targets:
          - "alertmanager.CLUSTER-monitoring.svc:9093"

    scrape_configs:
      - job_name: 'kubernetes-apiservers'
        kubernetes_sd_configs:
        - role: endpoints
        scheme: https
        tls_config:
          ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
        relabel_configs:
        - source_labels: [__meta_kubernetes_namespace, __meta_kubernetes_service_name, __meta_kubernetes_endpoint_port_name]
          action: keep
          regex: default;kubernetes;https

      - job_name: 'kubernetes-nodes'
        kubernetes_sd_configs:
        - role: node
        scheme: https
        tls_config:
          ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
        relabel_configs:
        - action: labelmap
          regex: __meta_kubernetes_node_label_(.+)
        - target_label: __address__
          replacement: kubernetes.default.svc:443
        - source_labels: [__meta_kubernetes_node_name]
          regex: (.+)
          target_label: __metrics_path__
          replacement: /api/v1/nodes/${1}/proxy/metrics

      - job_name: 'kubernetes-pods'
        kubernetes_sd_configs:
        - role: pod
        relabel_configs:
        - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
          action: keep
          regex: true
        - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
          action: replace
          target_label: __metrics_path__
          regex: (.+)
        - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]
          action: replace
          regex: ([^:]+)(?::\d+)?;(\d+)
          replacement: $1:$2
          target_label: __address__
        - action: labelmap
          regex: __meta_kubernetes_pod_label_(.+)
        - source_labels: [__meta_kubernetes_namespace]
          action: replace
          target_label: kubernetes_namespace
        - source_labels: [__meta_kubernetes_pod_name]
          action: replace
          target_label: kubernetes_pod_name

      - job_name: 'kubernetes-cadvisor'
        scheme: https
        tls_config:
          ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
        kubernetes_sd_configs:
        - role: node
        relabel_configs:
        - action: labelmap
          regex: __meta_kubernetes_node_label_(.+)
        - target_label: __address__
          replacement: kubernetes.default.svc:443
        - source_labels: [__meta_kubernetes_node_name]
          regex: (.+)
          target_label: __metrics_path__
          replacement: /api/v1/nodes/${1}/proxy/metrics/cadvisor

      - job_name: 'kubernetes-service-endpoints'
        kubernetes_sd_configs:
        - role: endpoints
        relabel_configs:
        - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scrape]
          action: keep
          regex: true
        - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scheme]
          action: replace
          target_label: __scheme__
          regex: (https?)
        - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_path]
          action: replace
          target_label: __metrics_path__
          regex: (.+)
        - source_labels: [__address__, __meta_kubernetes_service_annotation_prometheus_io_port]
          action: replace
          target_label: __address__
          regex: ([^:]+)(?::\d+)?;(\d+)
          replacement: $1:$2
        - action: labelmap
          regex: __meta_kubernetes_service_label_(.+)
        - source_labels: [__meta_kubernetes_namespace]
          action: replace
          target_label: kubernetes_namespace
        - source_labels: [__meta_kubernetes_service_name]
          action: replace
          target_label: kubernetes_name
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-rules
  labels:
    name: prometheus-rules
  namespace: CLUSTER-monitoring
data:
  # Differences between the appcluster prometheus and the reportcluster
  # prometheus begin here, since we'll want to be monitoring different things
  # in the reporting cluster. This is just a minimal example: you wouuld
  # ideally include monitors for all reporting components here. These are, like
  # in the application cluster, cluster-local alerts rather than being
  # aggregated across clusters.
  ruler-alerts.yaml: |-
    groups:
    - name: ruler alerts
      rules:
      - alert: thanos-rule Query DNS Failures
        annotations:
          description: Thanos Rule {{$labels.job}} has {{$value | humanize}}% of failing DNS queries for query endpoints.
          runbook_url: https://github.com/thanos-io/thanos/tree/main/mixin/runbook.md#alert-name-thanosrulequeryhighdnsfailures
          summary: Thanos Rule is having high number of DNS failures.
        expr: |
          (
            sum by (job, instance) (rate(thanos_rule_query_apis_dns_failures_total{job=~".*thanos-rule.*"}[5m]))
          /
            sum by (job, instance) (rate(thanos_rule_query_apis_dns_lookups_total{job=~".*thanos-rule.*"}[5m]))
          * 100 > 1
          )
        for: 15m
        labels:
          severity: warning
      - alert: thanos-rule Alertmanager DNS Failures
        annotations:
          description: Thanos Rule {{$labels.instance}} has {{$value | humanize}}% of failing DNS queries for Alertmanager endpoints.
          runbook_url: https://github.com/thanos-io/thanos/tree/main/mixin/runbook.md#alert-name-thanosrulealertmanagerhighdnsfailures
          summary: Thanos Rule is having high number of DNS failures.
        expr: |
          (
            sum by (job, instance) (rate(thanos_rule_alertmanagers_dns_failures_total{job=~".*thanos-rule.*"}[5m]))
          /
            sum by (job, instance) (rate(thanos_rule_alertmanagers_dns_lookups_total{job=~".*thanos-rule.*"}[5m]))
          * 100 > 1
          )
        for: 15m
        labels:
          severity: warning
      - alert: thanos-rule No Rule Evaluations
        annotations:
          description: Thanos Rule {{$labels.instance}} did not perform any rule evaluations in the past 10 minutes.
          runbook_url: https://github.com/thanos-io/thanos/tree/main/mixin/runbook.md#alert-name-thanosnoruleevaluations
          summary: Thanos Rule did not perform any rule evaluations.
        expr: |
          sum by (job, instance) (rate(prometheus_rule_evaluations_total{job=~".*thanos-rule.*"}[5m])) <= 0
            and
          sum by (job, instance) (thanos_rule_loaded_rules{job=~".*thanos-rule.*"}) > 0
        for: 5m
        labels:
          severity: critical
---
apiVersion: v1
kind: Service
metadata:
  name: thanos-store-gateway
  namespace: CLUSTER-monitoring
spec:
  selector:
    name: prometheus
  ports:
    - protocol: TCP
      port: 10901
      targetPort: 10901
  clusterIP: None
  type: ClusterIP
# The alertmanager config is the same as for the appcluster as well. Note that
# this is for alerts local to the reportcluster, eg. Grafana downtime and such
# would be reported here.
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: alertmanager
  namespace: CLUSTER-monitoring
spec:
  replicas: 2
  selector:
    matchLabels:
      name: alertmanager
  template:
    metadata:
      labels:
        name: alertmanager
      annotations:
        prometheus.io/scrape: 'true'
        prometheus.io/port: '9093'
    spec:
      containers:
        - name: alertmanager
          image: prom/alertmanager:v0.22.2
          imagePullPolicy: IfNotPresent
          ports:
          - containerPort: 9093
          volumeMounts:
          - name: config
            mountPath: /etc/alertmanager
      volumes:
      - name: config
        configMap:
          name: alertmanager-config
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: alertmanager-config
  namespace: CLUSTER-monitoring
data:
  alertmanager.yml: |-
    global:
      resolve_timeout: 5m

    route:
      group_by: ['alertname', 'cluster']
      group_wait: 10s
      group_interval: 10s
      repeat_interval: 1h
      receiver: 'webhook.site'

    receivers:
      - name: 'webhook.site'
        webhook_configs:
        - url: 'https://webhook.site/b46fe156-506d-4376-9050-93694845380b'
---
kind: Service
apiVersion: v1
metadata:
  name: alertmanager
  namespace: CLUSTER-monitoring
spec:
  selector:
    name: alertmanager
  ports:
  - protocol: TCP
    port: 9093
    targetPort: 9093
# Here's where we get to the stuff unique to the reporting cluster: Grafana
# will be used as a frontend for exploring all our Telemetry and be the only
# user-facing view into our system. Any Grafana instance in any reporting
# cluster should be able to query our long-term storage and/or our live app
# clusters as need be.
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: grafana
  namespace: CLUSTER-monitoring
spec:
  replicas: 2
  selector:
    matchLabels:
      name: grafana
  template:
    metadata:
      labels:
        name: grafana
      annotations:
        prometheus.io/scrape: 'true'
        prometheus.io/port: '3000'
    spec:
      containers:
        - name: grafana
          image: grafana/grafana:8.0.1
          imagePullPolicy: IfNotPresent
          ports:
            - name: grafana-http
              containerPort: 3000
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /robots.txt
              port: 3000
              scheme: HTTP
            initialDelaySeconds: 10
            periodSeconds: 30
            successThreshold: 1
            timeoutSeconds: 2
          livenessProbe:
            failureThreshold: 3
            initialDelaySeconds: 30
            periodSeconds: 10
            successThreshold: 1
            tcpSocket:
              port: 3000
            timeoutSeconds: 1
          volumeMounts:
          - name: config
            mountPath: /etc/grafana
          - name: dashboards
            mountPath: /var/lib/grafana/dashboards
          - name: provisioning-dashboards
            mountPath: /etc/grafana/provisioning/dashboards
          - name: provisioning-datasources
            mountPath: /etc/grafana/provisioning/datasources
      volumes:
      - name: config
        configMap:
          name: grafana-config
      - name: dashboards
        configMap:
          name: grafana-dashboards
      - name: provisioning-dashboards
        configMap:
          name: grafana-provisioning-dashboards
      - name: provisioning-datasources
        configMap:
          name: grafana-provisioning-datasources
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: grafana-config
  namespace: CLUSTER-monitoring
data:
  # Note that there's a whole bunch more you might want to configure about
  # Grafana. See:
  # https://grafana.com/docs/grafana/latest/administration/configuration/
  # For the set of things which matter to us, rather than being defaults used
  # for demo purposes, I've given an explanation inline.
  grafana.ini: |-
    [server]
    ; Once you expose this properly via an Ingress and real domain, you'll want
    ; to match this up. For example, you might expose this as a subdomain such
    ; as `grafana.thekev.in`
    http_port = 3000
    domain = localhost
    enable_gzip = true

    [session]
    ; Using anything outside of in-memory sessions will make load balancing
    ; across instances a bit tricky. Note the `sessionAffinity` config in our
    ; Service entry below ensures users hit the same instance if available.
    provider = memory

    [analytics]
    reporting_enabled = false
    check_for_updates = false

    [security]
    ; You'll definitely want to change these before exposing Grafana to the
    ; world. See the various `auth.*` options for the available providers.
    admin_user = admin
    admin_password = admin

    [snapshots]
    external_enabled = false

    [users]
    allow_sign_up = false
    allow_org_create = false
    auto_assign_org = true
    auto_assign_org_role = Viewer

    default_theme = dark

    [log]
    ; Since Promtail will be scraping console logs, we don't need to do
    ; anything complicated here.
    mode = console
    ;level = info

    [log.console]
    ;level =
    ;format = console

    [dashboards.json]
    ; We'll be pre-provisioning our dashboards below in a configmap. This will
    ; allow us to do cool things like including our dashboards in source
    ; control and ensuring they don't drift between Grafana instances.
    enabled = true
    path = /var/lib/grafana/dashboards

    [alerting]
    ; Grafana v8 introduced "ngalerts", which should allow us to view and
    ; interact with our configured alerts across all our clusters and across
    ; both Prometheus-style and ThanosRuler-style alerts. TODO finish
    ; configuring this.
    enabled = true
    ; Though we want to be able to view the alerts, we already have
    ; alertmanager for actually processing them. TODO investigate whether using
    ; Grafana here could simplify things.
    execute_alerts = false

    [metrics]
    ; ie. metrics which Prometheus will scrape and which will eventually be
    ; made available to Grafana. Meta monitoring!
    ;enabled = true
    ;interval_seconds  = 10

    [feature_toggles]
    ; See Grafana v8 alerts comment above.
    enable = ngalert
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: grafana-dashboards
  namespace: CLUSTER-monitoring
data:
  # This is a sample Grafana dashboard which will show off the three metrics
  # our sample app exposes. TODO: I should extend this further to include
  # interesting logs, traces, examplars, alert thresholds, etc, etc.
  app.json: |-
    {
      "annotations": {
        "list": [
          {
            "builtIn": 1,
            "datasource": "-- Grafana --",
            "enable": true,
            "hide": true,
            "iconColor": "rgba(0, 211, 255, 1)",
            "name": "Annotations & Alerts",
            "type": "dashboard"
          }
        ]
      },
      "editable": true,
      "gnetId": null,
      "graphTooltip": 0,
      "links": [],
      "panels": [
        {
          "aliasColors": {},
          "bars": false,
          "dashLength": 10,
          "dashes": false,
          "datasource": "thanos-querier",
          "fieldConfig": {
            "defaults": {},
            "overrides": []
          },
          "fill": 1,
          "fillGradient": 0,
          "gridPos": {
            "h": 8,
            "w": 12,
            "x": 0,
            "y": 0
          },
          "hiddenSeries": false,
          "id": 2,
          "legend": {
            "avg": false,
            "current": false,
            "max": false,
            "min": false,
            "show": true,
            "total": false,
            "values": false
          },
          "lines": true,
          "linewidth": 1,
          "nullPointMode": "null",
          "options": {
            "alertThreshold": true
          },
          "percentage": false,
          "pluginVersion": "7.5.7",
          "pointradius": 2,
          "points": false,
          "renderer": "flot",
          "seriesOverrides": [],
          "spaceLength": 10,
          "stack": false,
          "steppedLine": false,
          "targets": [
            {
              "exemplar": true,
              "expr": "max by (kubernetes_pod_name) (system_in_flight_total)",
              "interval": "",
              "legendFormat": "",
              "queryType": "randomWalk",
              "refId": "A"
            }
          ],
          "thresholds": [],
          "timeFrom": null,
          "timeRegions": [],
          "timeShift": null,
          "title": "Job Concurrency",
          "tooltip": {
            "shared": true,
            "sort": 0,
            "value_type": "individual"
          },
          "type": "graph",
          "xaxis": {
            "buckets": null,
            "mode": "time",
            "name": null,
            "show": true,
            "values": []
          },
          "yaxes": [
            {
              "format": "short",
              "label": null,
              "logBase": 1,
              "max": null,
              "min": null,
              "show": true
            },
            {
              "format": "short",
              "label": null,
              "logBase": 1,
              "max": null,
              "min": null,
              "show": true
            }
          ],
          "yaxis": {
            "align": false,
            "alignLevel": null
          }
        },
        {
          "aliasColors": {},
          "bars": false,
          "dashLength": 10,
          "dashes": false,
          "datasource": "thanos-querier",
          "fieldConfig": {
            "defaults": {},
            "overrides": []
          },
          "fill": 1,
          "fillGradient": 0,
          "gridPos": {
            "h": 8,
            "w": 12,
            "x": 12,
            "y": 0
          },
          "hiddenSeries": false,
          "id": 6,
          "legend": {
            "avg": false,
            "current": false,
            "max": false,
            "min": false,
            "show": true,
            "total": false,
            "values": false
          },
          "lines": true,
          "linewidth": 1,
          "nullPointMode": "null",
          "options": {
            "alertThreshold": true
          },
          "percentage": false,
          "pluginVersion": "7.5.7",
          "pointradius": 2,
          "points": false,
          "renderer": "flot",
          "seriesOverrides": [],
          "spaceLength": 10,
          "stack": false,
          "steppedLine": false,
          "targets": [
            {
              "exemplar": true,
              "expr": "histogram_quantile(0.90, sum by (stage, le) (rate(job_latency_seconds_bucket[5m])))",
              "interval": "",
              "legendFormat": "",
              "queryType": "randomWalk",
              "refId": "A"
            }
          ],
          "thresholds": [],
          "timeFrom": null,
          "timeRegions": [],
          "timeShift": null,
          "title": "Job Latency",
          "tooltip": {
            "shared": true,
            "sort": 0,
            "value_type": "individual"
          },
          "type": "graph",
          "xaxis": {
            "buckets": null,
            "mode": "time",
            "name": null,
            "show": true,
            "values": []
          },
          "yaxes": [
            {
              "format": "short",
              "label": null,
              "logBase": 1,
              "max": null,
              "min": null,
              "show": true
            },
            {
              "format": "short",
              "label": null,
              "logBase": 1,
              "max": null,
              "min": null,
              "show": true
            }
          ],
          "yaxis": {
            "align": false,
            "alignLevel": null
          }
        },
        {
          "aliasColors": {},
          "bars": false,
          "dashLength": 10,
          "dashes": false,
          "datasource": "thanos-querier",
          "fieldConfig": {
            "defaults": {},
            "overrides": []
          },
          "fill": 1,
          "fillGradient": 0,
          "gridPos": {
            "h": 8,
            "w": 12,
            "x": 0,
            "y": 8
          },
          "hiddenSeries": false,
          "id": 4,
          "legend": {
            "avg": false,
            "current": false,
            "max": false,
            "min": false,
            "show": true,
            "total": false,
            "values": false
          },
          "lines": true,
          "linewidth": 1,
          "nullPointMode": "null",
          "options": {
            "alertThreshold": true
          },
          "percentage": false,
          "pluginVersion": "7.5.7",
          "pointradius": 2,
          "points": false,
          "renderer": "flot",
          "seriesOverrides": [],
          "spaceLength": 10,
          "stack": false,
          "steppedLine": false,
          "targets": [
            {
              "exemplar": true,
              "expr": "sum(rate(job_failures_total[5m])) / sum(rate(job_latency_seconds_count[5m]))",
              "interval": "",
              "legendFormat": "",
              "queryType": "randomWalk",
              "refId": "A"
            }
          ],
          "thresholds": [],
          "timeFrom": null,
          "timeRegions": [],
          "timeShift": null,
          "title": "Error Rate",
          "tooltip": {
            "shared": true,
            "sort": 0,
            "value_type": "individual"
          },
          "type": "graph",
          "xaxis": {
            "buckets": null,
            "mode": "time",
            "name": null,
            "show": true,
            "values": []
          },
          "yaxes": [
            {
              "format": "short",
              "label": null,
              "logBase": 1,
              "max": null,
              "min": null,
              "show": true
            },
            {
              "format": "short",
              "label": null,
              "logBase": 1,
              "max": null,
              "min": null,
              "show": true
            }
          ],
          "yaxis": {
            "align": false,
            "alignLevel": null
          }
        }
      ],
      "schemaVersion": 27,
      "style": "dark",
      "tags": [],
      "time": {
        "from": "now-6h",
        "to": "now"
      },
      "timepicker": {},
      "timezone": "",
      "title": "App",
      "uid": "9tVG70eMz",
      "version": 1
    }
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: grafana-provisioning-dashboards
  namespace: CLUSTER-monitoring
data:
  default.yaml: |-
    apiVersion: 1
    providers:
      # This will allow Grafana to load defined dashboards (such as the
      # app.json file above) from disk on startup, to ensure all Grafana
      # instances get the same configs.
      - name: preload
        type: file
        # We'll disable deletion and modification in the UI to ensure users
        # must check changes into source control and prevent our instance
        # configs from drifting or having changes be lost on pod restart.
        disableDeletion: true
        updateIntervalSeconds: 10
        allowUiUpdates: false
        options:
          path: /var/lib/grafana/dashboards
          foldersFromFilesStructure: true
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: grafana-provisioning-datasources
  namespace: CLUSTER-monitoring
data:
  # We'll also provision the various datasources which users may want to query:
  # loki for logs, tempo for traces, and thanos-querier for metrics. Note that
  # each will be explained below, but it's worth mentioning now that each of
  # these endpoints is cluster local rather than being eg. in an app cluster.
  loki.yaml: |-
    apiVersion: 1
    datasources:
      - name: loki
        type: loki
        access: proxy
        uid: loki
        url: "http://loki:3100"
        version: 1
  tempo.yaml: |-
    apiVersion: 1
    datasources:
      - name: tempo
        type: tempo
        access: proxy
        uid: tempo
        url: "http://tempo:3100"
        version: 1
  prometheus.yaml: |-
    apiVersion: 1
    datasources:
      - name: thanos-querier
        type: prometheus
        access: proxy
        uid: thanos-querier
        url: "http://thanos-querier:10902"
        version: 1
---
apiVersion: v1
kind: Service
metadata:
  name: grafana
  namespace: CLUSTER-monitoring
spec:
  selector:
    name: grafana
  ports:
    - protocol: TCP
      port: 3000
      targetPort: 3000
  # Note that this is the only Service which is meant to be used outside the
  # cluster, so I've assigned it here a session affinity to ensure users hit
  # the same instance when possible to avoid invalidating their session.
  # In the real world, you'll likely want to add an Ingress path along with tls
  # certs, etc. See also configuring Grafana for actual auth above.
  sessionAffinity: ClientIP
  type: LoadBalancer
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: thanos-store-gateway-longterm
  namespace: CLUSTER-monitoring
spec:
  replicas: 2
  selector:
    matchLabels:
      name: thanos-store-gateway-longterm
  template:
    metadata:
      labels:
        name: thanos-store-gateway-longterm
    spec:
      containers:
        # This Thanos instance is a bit different than the others in the app
        # clusters -- it is not a sidecar, but rather an instance of the Thanos
        # Store API. Rather than being responsible for accepting any metrics,
        # it is used strictly to *pull* long term metrics down from our
        # permanent storage and make them available to Grafana.
        # In essence, to query all available metrics we will need to query the
        # normal thanos-store-gateway in each cluster (for recent metrics on
        # that cluster) *and* the thanos-store-gateway-longterm here (for older
        # metrics on all clusters). We'll get to that eventually.
        - name: thanos
          image: thanosio/thanos:v0.21.1
          args:
          - 'store'
          - '--log.level=info'
          - '--data-dir=/data'
          - '--objstore.config={type: GCS, config: {bucket: kjames-prometheus-longterm}}'
          - '--index-cache-size=500MB'
          - '--chunk-pool-size=500MB'
          env:
            - name : GOOGLE_APPLICATION_CREDENTIALS
              value: /etc/secret/adc.json
          ports:
          - name: thanos-api
            containerPort: 10902
          - name: prometheus-api
            containerPort: 10901
          livenessProbe:
            httpGet:
              port: 10902
              path: /-/healthy
          readinessProbe:
            httpGet:
              port: 10902
              path: /-/ready
          volumeMounts:
            - name: thanos-gcs-creds
              mountPath: /etc/secret
              readOnly: false
      volumes:
        - name: thanos-gcs-creds
          secret:
            secretName: thanos-gcs-creds
---
apiVersion: v1
kind: Service
metadata:
  name: thanos-store-gateway-longterm
  namespace: CLUSTER-monitoring
spec:
  selector:
    name: thanos-store-gateway-longterm
  ports:
    - protocol: TCP
      port: 10901
      targetPort: 10901
  clusterIP: None
  type: ClusterIP
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: thanos-querier
  namespace: CLUSTER-monitoring
spec:
  replicas: 2
  selector:
    matchLabels:
      name: thanos-querier
  template:
    metadata:
      labels:
        name: thanos-querier
    spec:
      containers:
      # Speaking of Thanos deployments with different goals, this one is the
      # querier. This is the only one which Grafana will hit *directly* and
      # will be responsible for fanning out to whichever other instance might
      # be relevant to the query.
      # We'll need to list here all the prometheus endpoints which we want to
      # be able to query.
      - name: thanos
        image: thanosio/thanos:v0.21.1
        args:
        - 'query'
        - '--log.level=info'
        # As mentioned way back when in the appcluster config, we'll be using
        # this "replica" label to de-duplicate results. Identical metrics with
        # differing replica values will be deduped to allow us to run multiple
        # prometheus instances scraping the same data.
        - '--query.replica-label=replica'
        # Note that referencing the non-longterm gateways is not strictly
        # necessary here and does introduce the requirement that your reporting
        # cluster must be able to enumerate your application clusters.
        # By including this here, we allow our dashboards to include fully
        # up-to-date metrics. If we only care to explore long-term data, this
        # is not necessary.
        # Note that since alertmanager is also running locally in each cluster
        # for cluster-local metrics, omitting these would not impact having
        # realtime alerting (for *non-cluster-aggregated alerts*, see Thanos
        # Rules config).
        # Another option, not explored in this demo, would be to run Grafana
        # instances in each cluster or make them trivial to spin up for adhoc
        # cases where you need more up-to-date metrics. That flow may provide
        # a happy medium wherein the reporting clusters can be agnostic of our
        # application clusters and debugging of realtime metrics can be
        # performed as need be. Since the Thanos gateways are already running
        # in each cluster, it would simply be a matter of spinning up a
        # temporary Grafana pointed to the given address: a saved `kubectl run`
        # command could probably do the trick!
        - '--store=thanos-store-gateway.appcluster-a-monitoring.svc:10901'
        - '--store=thanos-store-gateway.appcluster-b-monitoring.svc:10901'
        - '--store=thanos-store-gateway.CLUSTER-monitoring.svc:10901'
        - '--store=thanos-store-gateway-longterm.CLUSTER-monitoring.svc:10901'
        - '--store=thanos-ruler.CLUSTER-monitoring.svc:10901'
        ports:
        - name: thanos-http
          containerPort: 10902
        - name: prometheus-api
          containerPort: 10901
        livenessProbe:
          httpGet:
            port: thanos-http
            path: /-/healthy
        readinessProbe:
          httpGet:
            port: thanos-http
            path: /-/ready
---
apiVersion: v1
kind: Service
metadata:
  name: thanos-querier
  namespace: CLUSTER-monitoring
spec:
  selector:
    name: thanos-querier
  ports:
  # TODO: I think this implies I misunderstood the whole thanos-http vs
  # prometheus-api thing... looks like both are the API and the former is just
  # *also* the website? Likely http vs grpc, so we could probably switch this
  # over to grpc and nuke the http configs globally / clarify that they're
  # exposed solely for demo purposes. Is there any reason we'd need the http
  # endpoints in prod?
  - protocol: TCP
    port: 10902
    targetPort: 10902
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: thanos-compactor
  namespace: CLUSTER-monitoring
spec:
  # This is the only system not deployed with multiple replicas in this demo.
  # Note that this is intentional -- the Thanos Compactor must be run as a
  # singleton and does not pose a system availability issue if it is not
  # running since it is purely for optimization purposes.
  # See https://thanos.io/tip/thanos/quick-tutorial.md/#compactor
  # TODO: figure out a way to keep this a singleton with multiple reporting
  # clusters.
  replicas: 1
  selector:
    matchLabels:
      name: thanos-compactor
  template:
    metadata:
      labels:
        name: thanos-compactor
    spec:
      containers:
        - name: thanos
          image: thanosio/thanos:v0.21.1
          args:
            - 'compact'
            - '--log.level=info'
            - '--data-dir=/data'
            - '--objstore.config={type: GCS, config: {bucket: kjames-prometheus-longterm}}'
            - '--wait'
          env:
            - name: GOOGLE_APPLICATION_CREDENTIALS
              value: /etc/secret/adc.json
          ports:
            - name: thanos-http
              containerPort: 10902
          livenessProbe:
            httpGet:
              port: 10902
              path: /-/healthy
          readinessProbe:
            httpGet:
              port: 10902
              path: /-/ready
          volumeMounts:
            - name: thanos-gcs-creds
              mountPath: /etc/secret
              readOnly: false
      volumes:
        - name: thanos-gcs-creds
          secret:
            secretName: thanos-gcs-creds
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: thanos-ruler
  namespace: CLUSTER-monitoring
spec:
  replicas: 2
  selector:
    matchLabels:
      name: thanos-ruler
  template:
    metadata:
      labels:
        name: thanos-ruler
    spec:
      containers:
        # The Thanos Ruler is Thanos' implementation of the Prometheus rules
        # engine, which is capable of alerting upon aggregated data. Alerts
        # here should be used lightly (see risks section mentioned in the
        # config) and only for things which require that level of aggregation;
        # eg. think system-wide SLOs with daily reports rather than realtime
        # alerts of downtime.
        - name: thanos
          image: thanosio/thanos:v0.21.1
          args:
            - 'rule'
            - '--log.level=info'
            - '--data-dir=/data'
            - '--eval-interval=15s'
            - '--rule-file=/etc/thanos-ruler/*.yaml'
            # We'll reuse the alertmanager in this cluster for sending out the
            # alerts -- no need to have a second alertmanager, since Thanos
            # Ruler knows how to emit things in standard Prometheus format.
            - '--alertmanagers.url=http://alertmanager.CLUSTER-monitoring.svc:9093'
            # We'll be querying the thanos-querier service defined above, which
            # lets us fan out to all available metric sources.
            - '--query=thanos-querier.CLUSTER-monitoring.svc:10902'
            - '--objstore.config={type: GCS, config: {bucket: kjames-thanos-ruler}}'
            # Note that we do the same grouping and deduping logic as we do in
            # our non-aggregated alerts, since we can have multiple Thanos
            # Ruler instances in the same reporting cluster (or even multiple
            # alerting clusters) and those need to get deduped as well.
            - '--label=ruler_cluster="$(POD_NAMESPACE)"'
            - '--label=replica="$(POD_NAME)"'
          env:
            - name : GOOGLE_APPLICATION_CREDENTIALS
              value: /etc/secret/adc.json
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: POD_NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
          ports:
            - name: thanos-http
              containerPort: 10902
            - name: prometheus-api
              containerPort: 10901
          livenessProbe:
            httpGet:
              port: 10902
              path: /-/healthy
          readinessProbe:
            httpGet:
              port: 10902
              path: /-/ready
          volumeMounts:
            - name: config
              mountPath: /etc/thanos-ruler
            - name: thanos-gcs-creds
              mountPath: /etc/secret
              readOnly: false
      volumes:
        - name: config
          configMap:
            name: thanos-ruler-rules
        - name: thanos-gcs-creds
          secret:
            secretName: thanos-gcs-creds
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: thanos-ruler-rules
  namespace: CLUSTER-monitoring
data:
  # Note that these are the previously-mentioned Thanos Ruler alerts, eg. those
  # which apply to the entire set of aggregated clusters we're managing. See
  # again the following doc for why you should use these as lightly as
  # possible:
  # https://thanos.io/tip/components/rule.md/#risk
  prometheus.yaml: |
    groups:
    - name: global prometheus alerts
      rules:
      - alert: Prometheus Replica Down
        annotations:
          message: Prometheus replica in cluster {{$labels.cluster}} has disappeared from Prometheus target discovery.
        # TODO: this expression doesn't look right
        expr: sum(up{instance=~".*:9090", job="kubernetes-service-endpoints"}) by (job,cluster) < 2
        for: 15s
        labels:
          severity: critical
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app: thanos-ruler
  name: thanos-ruler
  namespace: CLUSTER-monitoring
spec:
  selector:
    name: thanos-ruler
  ports:
    - protocol: TCP
      name: grpc
      port: 10901
      targetPort: 10901
    - protocol: TCP
      name: http
      port: 10902
      targetPort: 10902
# Promtail is configured the same way here as in the app cluster; we want to
# scrape logs from eg. Grafana as well as our own apps!
---
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: promtail
  namespace: CLUSTER-monitoring
spec:
  selector:
    matchLabels:
      name: promtail
  template:
    metadata:
      labels:
        name: promtail
    spec:
      containers:
        - name: promtail
          image: grafana/promtail:2.2.1
          args:
          - '-config.file=/etc/promtail/promtail.yaml'
          env:
          - name: HOSTNAME
            valueFrom:
              fieldRef:
                fieldPath: spec.nodeName
          readinessProbe:
            httpGet:
              path: /ready
              port: 80
              scheme: HTTP
            initialDelaySeconds: 10
          ports:
            - name: promtail-http
              containerPort: 80
          securityContext:
            privileged: true
            runAsUser: 0
          volumeMounts:
          - name: config
            mountPath: /etc/promtail
          - name: logs-docker
            mountPath: /var/lib/docker/containers
            readOnly: true
          - name: logs-varlog
            mountPath: /var/log
      volumes:
      - name: config
        configMap:
          name: promtail-config
      - name: logs-varlog
        hostPath:
          path: /var/log
      - name: logs-docker
        hostPath:
          path: /var/lib/docker/containers
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: promtail-config
  namespace: CLUSTER-monitoring
data:
  promtail.yaml: |-
    server:
      http_listen_port: 0
      grpc_listen_port: 0

    positions:
      filename: /tmp/positions.yaml

    clients:
      - url: http://loki.CLUSTER-monitoring.svc:3100/loki/api/v1/push

    scrape_configs:
    - job_name: kubernetes-pods-name
      kubernetes_sd_configs:
      - role: pod
      pipeline_stages: []
      relabel_configs:
      - source_labels:
        - __meta_kubernetes_pod_label_name
        target_label: __service__
      - source_labels:
        - __meta_kubernetes_pod_node_name
        target_label: __host__
      - action: drop
        regex: '^$'
        source_labels:
        - __service__
      - action: replace
        replacement: '$1'
        separator: '/'
        source_labels:
        - __meta_kubernetes_namespace
        - __service__
        target_label: job
      - action: replace
        source_labels:
        - __meta_kubernetes_namespace
        target_label: namespace
      - action: replace
        source_labels:
        - __meta_kubernetes_pod_name
        target_label: instance
      - action: replace
        source_labels:
        - __meta_kubernetes_pod_container_name
        target_label: container_name
      - replacement: '/var/log/pods/*$1/*.log'
        separator: '/'
        source_labels:
        - __meta_kubernetes_pod_uid
        - __meta_kubernetes_pod_container_name
        target_label: __path__
    - job_name: kubernetes-pods-app
      kubernetes_sd_configs:
      - role: pod
      pipeline_stages: []
      relabel_configs:
      - action: drop
        regex: '.+'
        source_labels:
        - __meta_kubernetes_pod_label_name
      - source_labels:
        - __meta_kubernetes_pod_label_app
        target_label: __service__
      - source_labels:
        - __meta_kubernetes_pod_node_name
        target_label: __host__
      - action: drop
        regex: '^$'
        source_labels:
        - __service__
      - action: replace
        replacement: '$1'
        separator: '/'
        source_labels:
        - __meta_kubernetes_namespace
        - __service__
        target_label: job
      - action: replace
        source_labels:
        - __meta_kubernetes_namespace
        target_label: namespace
      - action: replace
        source_labels:
        - __meta_kubernetes_pod_name
        target_label: instance
      - action: replace
        source_labels:
        - __meta_kubernetes_pod_container_name
        target_label: container_name
      - replacement: '/var/log/pods/*$1/*.log'
        separator: '/'
        source_labels:
        - __meta_kubernetes_pod_uid
        - __meta_kubernetes_pod_container_name
        target_label: __path__
    - job_name: kubernetes-pods-direct-controllers
      kubernetes_sd_configs:
      - role: pod
      pipeline_stages: []
      relabel_configs:
      - action: drop
        regex: '.+'
        separator: ''
        source_labels:
        - __meta_kubernetes_pod_label_name
        - __meta_kubernetes_pod_label_app
      - action: drop
        regex: '^([0-9a-z-.]+)(-[0-9a-f]{8,10})$'
        source_labels:
        - __meta_kubernetes_pod_controller_name
      - source_labels:
        - __meta_kubernetes_pod_controller_name
        target_label: __service__
      - source_labels:
        - __meta_kubernetes_pod_node_name
        target_label: __host__
      - action: drop
        regex: '^$'
        source_labels:
        - __service__
      - action: replace
        replacement: '$1'
        separator: /
        source_labels:
        - __meta_kubernetes_namespace
        - __service__
        target_label: job
      - action: replace
        source_labels:
        - __meta_kubernetes_namespace
        target_label: namespace
      - action: replace
        source_labels:
        - __meta_kubernetes_pod_name
        target_label: instance
      - action: replace
        source_labels:
        - __meta_kubernetes_pod_container_name
        target_label: container_name
      - replacement: '/var/log/pods/*$1/*.log'
        separator: /
        source_labels:
        - __meta_kubernetes_pod_uid
        - __meta_kubernetes_pod_container_name
        target_label: __path__
    - job_name: kubernetes-pods-indirect-controller
      kubernetes_sd_configs:
      - role: pod
      pipeline_stages: []
      relabel_configs:
      - action: drop
        regex: '.+'
        separator: ''
        source_labels:
        - __meta_kubernetes_pod_label_name
        - __meta_kubernetes_pod_label_app
      - action: keep
        regex: '^([0-9a-z-.]+)(-[0-9a-f]{8,10})$'
        source_labels:
        - __meta_kubernetes_pod_controller_name
      - action: replace
        regex: '^([0-9a-z-.]+)(-[0-9a-f]{8,10})$'
        source_labels:
        - __meta_kubernetes_pod_controller_name
        target_label: __service__
      - source_labels:
        - __meta_kubernetes_pod_node_name
        target_label: __host__
      - action: drop
        regex: '^$'
        source_labels:
        - __service__
      - action: replace
        replacement: '$1'
        separator: '/'
        source_labels:
        - __meta_kubernetes_namespace
        - __service__
        target_label: job
      - action: replace
        source_labels:
        - __meta_kubernetes_namespace
        target_label: namespace
      - action: replace
        source_labels:
        - __meta_kubernetes_pod_name
        target_label: instance
      - action: replace
        source_labels:
        - __meta_kubernetes_pod_container_name
        target_label: container_name
      - replacement: '/var/log/pods/*$1/*.log'
        separator: '/'
        source_labels:
        - __meta_kubernetes_pod_uid
        - __meta_kubernetes_pod_container_name
        target_label: __path__
    - job_name: kubernetes-pods-static
      kubernetes_sd_configs:
      - role: pod
      pipeline_stages: []
      relabel_configs:
      - action: drop
        regex: '^$'
        source_labels:
        - __meta_kubernetes_pod_annotation_kubernetes_io_config_mirror
      - action: replace
        source_labels:
        - __meta_kubernetes_pod_label_component
        target_label: __service__
      - source_labels:
        - __meta_kubernetes_pod_node_name
        target_label: __host__
      - action: drop
        regex: '^$'
        source_labels:
        - __service__
      - action: replace
        replacement: '$1'
        separator: '/'
        source_labels:
        - __meta_kubernetes_namespace
        - __service__
        target_label: job
      - action: replace
        source_labels:
        - __meta_kubernetes_namespace
        target_label: namespace
      - action: replace
        source_labels:
        - __meta_kubernetes_pod_name
        target_label: instance
      - action: replace
        source_labels:
        - __meta_kubernetes_pod_container_name
        target_label: container_name
      - replacement: '/var/log/pods/*$1/*.log'
        separator: '/'
        source_labels:
        - __meta_kubernetes_pod_annotation_kubernetes_io_config_mirror
        - __meta_kubernetes_pod_container_name
        target_label: __path__
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: loki
  namespace: CLUSTER-monitoring
spec:
  replicas: 2
  selector:
    matchLabels:
      name: loki
  template:
    metadata:
      labels:
        name: loki
    spec:
      containers:
        # TODO: this needs to get split apart -- currently this Loki instance
        # is handling ingestion directly from the app clusters, which isn't
        # correct. Ideally, this would be readonly (or, both, I suppose, since
        # we want to ingest local logs...) and the appclusters would have
        # writeonly versions.
        - name: loki
          image: grafana/loki:2.2.1
          args:
          - '-config.file=/etc/loki/loki.yaml'
          env:
            - name: GOOGLE_APPLICATION_CREDENTIALS
              value: /etc/secret/adc.json
          ports:
            # TODO: figure out these ports
            - name: loki-http
              containerPort: 3100
            - name: loki-grpc
              containerPort: 9096
          volumeMounts:
            # TODO: pvc for ingestor storage
            - name: config
              mountPath: /etc/loki
            - name: thanos-gcs-creds
              mountPath: /etc/secret
              readOnly: false
      volumes:
        - name: config
          configMap:
            name: loki-config
        - name: thanos-gcs-creds
          secret:
            secretName: thanos-gcs-creds
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: loki-config
  namespace: CLUSTER-monitoring
data:
  # TODO: split this apart a bit (defaults to all features enabled). Need to
  # split compactor, at least, since it's supposed to be a singleton
  loki.yaml: |-
    auth_enabled: false

    server:
      http_listen_port: 3100
      grpc_listen_port: 9096

    ingester:
      wal:
        enabled: true
        dir: /tmp/wal
      lifecycler:
        address: 127.0.0.1
        ring:
          kvstore:
            store: inmemory
          replication_factor: 1
        final_sleep: 0s
      chunk_idle_period: 10m
      max_chunk_age: 10m
      chunk_target_size: 1048576
      chunk_retain_period: 30s
      max_transfer_retries: 0

    schema_config:
      configs:
        - from: 2000-01-01
          store: boltdb-shipper
          object_store: gcs
          schema: v11
          index:
            prefix: index_
            period: 24h

    storage_config:
      boltdb_shipper:
        active_index_directory: /tmp/loki/index
        shared_store: gcs
        cache_location: /tmp/loki/boltdb-cache
      gcs:
        bucket_name: kjames-loki

    compactor:
      working_directory: /tmp/loki/compactor
      shared_store: filesystem
      compaction_interval: 5m

    limits_config:
      reject_old_samples: true
      reject_old_samples_max_age: 168h

    chunk_store_config:
      max_look_back_period: 0s

    table_manager:
      retention_deletes_enabled: false
      retention_period: 0s

    ruler:
      storage:
        type: local
        local:
          directory: /tmp/loki/rules
      rule_path: /tmp/loki/rules-temp
      alertmanager_url: http://alertmanager.CLUSTER-monitoring.svc:9093
      ring:
        kvstore:
          store: inmemory
      enable_api: true
---
apiVersion: v1
kind: Service
metadata:
  name: loki
  namespace: CLUSTER-monitoring
spec:
  selector:
    name: loki
  ports:
    - protocol: TCP
      port: 3100
      targetPort: 3100
  clusterIP: None
  type: ClusterIP
# Finally, Tempo is responsible for dealing with traces. Since we don't have
# anything relevant to trace within the reporting clusters, the Tempo config
# here doesn't need to worry about ingestion and can be focused solely on being
# queryable by Grafana.
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: tempo
  namespace: CLUSTER-monitoring
spec:
  replicas: 2
  selector:
    matchLabels:
      name: tempo
  template:
    metadata:
      labels:
        name: tempo
    spec:
      containers:
        - name: tempo
          image: grafana/tempo:1.0.1
          args:
          - '-config.file=/etc/tempo/tempo.yaml'
          env:
            - name: GOOGLE_APPLICATION_CREDENTIALS
              value: /etc/secret/adc.json
          ports:
            # TODO: naming?
            - name: tempo-api
              containerPort: 3100
            - name: metrics
              containerPort: 9095
          volumeMounts:
            - name: config
              mountPath: /etc/tempo
            - name: thanos-gcs-creds
              mountPath: /etc/secret
              readOnly: false
      volumes:
        - name: config
          configMap:
            name: tempo-config
        - name: thanos-gcs-creds
          secret:
            secretName: thanos-gcs-creds
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: tempo-config
  namespace: CLUSTER-monitoring
data:
  tempo.yaml: |-
    server:
      http_listen_port: 3100

    # TODO: note that every Tempo instance includes the distributor and
    # ingestor (for ingestion), the querier and query-frontend (for querying),
    # and the compactor (for ongoing maintenance of long-term storage). I would
    # love to figure out how to disable the distributor and ingestor within the
    # reporting clusters.

    distributor:
      receivers:
        otlp:
          protocols:
            grpc:

    compactor:
      compaction:
        block_retention: 168h
        compacted_block_retention: 10m
        compaction_window: 1h
      ring:
        kvstore:
          store: memberlist

    storage:
      trace:
        backend: gcs
        block:
          bloom_filter_false_positive: .05
          index_downsample_bytes: 1000
          encoding: zstd
        wal:
          path: /tmp/tempo/wal
          encoding: none
        gcs:
          bucket_name: kjames-tempo
        pool:
          max_workers: 100
          queue_depth: 10000
---
apiVersion: v1
kind: Service
metadata:
  name: tempo
  namespace: CLUSTER-monitoring
spec:
  selector:
    name: tempo
  ports:
    - protocol: TCP
      port: 3100
      targetPort: 3100
  clusterIP: None
  type: ClusterIP
