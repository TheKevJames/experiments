---
apiVersion: v1
kind: Namespace
metadata:
  name: CLUSTER-monitoring
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-config
  namespace: CLUSTER-monitoring
data:
  prometheus.yaml.tmpl: |-
    global:
      scrape_interval: 60s
      evaluation_interval: 5s
      external_labels:
        # N.B. see notes on namespace as cluster emulation
        cluster: $(POD_NAMESPACE)
        replica: $(POD_NAME)

    rule_files:
      - /etc/prometheus/rules/*.yaml

    alerting:
      alert_relabel_configs:
      - regex: replica
        action: labeldrop

      alertmanagers:
      - scheme: http
        static_configs:
        - targets:
          - "alertmanager.CLUSTER-monitoring.svc:9093"

    scrape_configs:
      - job_name: 'kubernetes-apiservers'
        kubernetes_sd_configs:
        - role: endpoints
        scheme: https
        tls_config:
          ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
        relabel_configs:
        - source_labels: [__meta_kubernetes_namespace, __meta_kubernetes_service_name, __meta_kubernetes_endpoint_port_name]
          action: keep
          regex: default;kubernetes;https

      - job_name: 'kubernetes-nodes'
        kubernetes_sd_configs:
        - role: node
        scheme: https
        tls_config:
          ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
        relabel_configs:
        - action: labelmap
          regex: __meta_kubernetes_node_label_(.+)
        - target_label: __address__
          replacement: kubernetes.default.svc:443
        - source_labels: [__meta_kubernetes_node_name]
          regex: (.+)
          target_label: __metrics_path__
          replacement: /api/v1/nodes/${1}/proxy/metrics

      - job_name: 'kubernetes-pods'
        kubernetes_sd_configs:
        - role: pod
        relabel_configs:
        - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
          action: keep
          regex: true
        - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
          action: replace
          target_label: __metrics_path__
          regex: (.+)
        - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]
          action: replace
          regex: ([^:]+)(?::\d+)?;(\d+)
          replacement: $1:$2
          target_label: __address__
        - action: labelmap
          regex: __meta_kubernetes_pod_label_(.+)
        - source_labels: [__meta_kubernetes_namespace]
          action: replace
          target_label: kubernetes_namespace
        - source_labels: [__meta_kubernetes_pod_name]
          action: replace
          target_label: kubernetes_pod_name

      - job_name: 'kubernetes-cadvisor'
        scheme: https
        tls_config:
          ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
        kubernetes_sd_configs:
        - role: node
        relabel_configs:
        - action: labelmap
          regex: __meta_kubernetes_node_label_(.+)
        - target_label: __address__
          replacement: kubernetes.default.svc:443
        - source_labels: [__meta_kubernetes_node_name]
          regex: (.+)
          target_label: __metrics_path__
          replacement: /api/v1/nodes/${1}/proxy/metrics/cadvisor

      - job_name: 'kubernetes-service-endpoints'
        kubernetes_sd_configs:
        - role: endpoints
        relabel_configs:
        - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scrape]
          action: keep
          regex: true
        - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scheme]
          action: replace
          target_label: __scheme__
          regex: (https?)
        - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_path]
          action: replace
          target_label: __metrics_path__
          regex: (.+)
        - source_labels: [__address__, __meta_kubernetes_service_annotation_prometheus_io_port]
          action: replace
          target_label: __address__
          regex: ([^:]+)(?::\d+)?;(\d+)
          replacement: $1:$2
        - action: labelmap
          regex: __meta_kubernetes_service_label_(.+)
        - source_labels: [__meta_kubernetes_namespace]
          action: replace
          target_label: kubernetes_namespace
        - source_labels: [__meta_kubernetes_service_name]
          action: replace
          target_label: kubernetes_name
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-rules
  labels:
    name: prometheus-rules
  namespace: CLUSTER-monitoring
data:
  ruler-alerts.yaml: |-
    groups:
    - name: ruler alerts
      rules:
      - alert: thanos-rule Query DNS Failures
        annotations:
          description: Thanos Rule {{$labels.job}} has {{$value | humanize}}% of failing DNS queries for query endpoints.
          runbook_url: https://github.com/thanos-io/thanos/tree/main/mixin/runbook.md#alert-name-thanosrulequeryhighdnsfailures
          summary: Thanos Rule is having high number of DNS failures.
        expr: |
          (
            sum by (job, instance) (rate(thanos_rule_query_apis_dns_failures_total{job=~".*thanos-rule.*"}[5m]))
          /
            sum by (job, instance) (rate(thanos_rule_query_apis_dns_lookups_total{job=~".*thanos-rule.*"}[5m]))
          * 100 > 1
          )
        for: 15m
        labels:
          severity: warning
      - alert: thanos-rule Alertmanager DNS Failures
        annotations:
          description: Thanos Rule {{$labels.instance}} has {{$value | humanize}}% of failing DNS queries for Alertmanager endpoints.
          runbook_url: https://github.com/thanos-io/thanos/tree/main/mixin/runbook.md#alert-name-thanosrulealertmanagerhighdnsfailures
          summary: Thanos Rule is having high number of DNS failures.
        expr: |
          (
            sum by (job, instance) (rate(thanos_rule_alertmanagers_dns_failures_total{job=~".*thanos-rule.*"}[5m]))
          /
            sum by (job, instance) (rate(thanos_rule_alertmanagers_dns_lookups_total{job=~".*thanos-rule.*"}[5m]))
          * 100 > 1
          )
        for: 15m
        labels:
          severity: warning
      - alert: thanos-rule No Rule Evaluations
        annotations:
          description: Thanos Rule {{$labels.instance}} did not perform any rule evaluations in the past 10 minutes.
          runbook_url: https://github.com/thanos-io/thanos/tree/main/mixin/runbook.md#alert-name-thanosnoruleevaluations
          summary: Thanos Rule did not perform any rule evaluations.
        expr: |
          sum by (job, instance) (rate(prometheus_rule_evaluations_total{job=~".*thanos-rule.*"}[5m])) <= 0
            and
          sum by (job, instance) (thanos_rule_loaded_rules{job=~".*thanos-rule.*"}) > 0
        for: 5m
        labels:
          severity: critical
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: prometheus
  namespace: CLUSTER-monitoring
spec:
  replicas: 2
  selector:
    matchLabels:
      name: prometheus
  template:
    metadata:
      labels:
        name: prometheus
      annotations:
        prometheus.io/scrape: 'true'
        prometheus.io/port: '9090'
    spec:
      containers:
        - name: prometheus
          image: prom/prometheus:v2.27.1
          imagePullPolicy: IfNotPresent
          args:
            - '--config.file=/etc/prometheus-shared/prometheus.yaml'
            - '--storage.tsdb.path=/prometheus/'
            - '--web.enable-lifecycle'
            - '--storage.tsdb.no-lockfile'
            # N.B. this should almost certainly be higher in production (Thanos recommends 2h).
            # I have it set low here only for demo purposes.
            - '--storage.tsdb.min-block-duration=10m'
            - '--storage.tsdb.max-block-duration=10m'
            # N.B. this should be "not less than 3x the block size"
            - '--storage.tsdb.retention.time=1h'
          ports:
            - containerPort: 9090
          volumeMounts:
            - name: prometheus-config-shared
              mountPath: /etc/prometheus-shared/
            - name: prometheus-rules
              mountPath: /etc/prometheus/rules
            - name: prometheus-storage
              mountPath: /prometheus/
        - name: thanos
          image: thanosio/thanos:v0.21.1
          args:
            - 'sidecar'
            - '--log.level=info'
            - '--tsdb.path=/prometheus/'
            - '--prometheus.url=http://127.0.0.1:9090'
            - '--objstore.config={type: GCS, config: {bucket: kjames-prometheus-longterm}}'
            - '--reloader.config-file=/etc/prometheus/prometheus.yaml.tmpl'
            - '--reloader.config-envsubst-file=/etc/prometheus-shared/prometheus.yaml'
            - '--reloader.rule-dir=/etc/prometheus/rules/'
          env:
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: POD_NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            - name: GOOGLE_APPLICATION_CREDENTIALS
              value: /etc/secret/adc.json
          ports:
            - name: http-sidecar
              containerPort: 10902
            - name: grpc
              containerPort: 10901
          livenessProbe:
            httpGet:
              port: 10902
              path: /-/healthy
          readinessProbe:
            httpGet:
              port: 10902
              path: /-/ready
          volumeMounts:
            - name: prometheus-config
              mountPath: /etc/prometheus
            - name: prometheus-config-shared
              mountPath: /etc/prometheus-shared/
            - name: prometheus-rules
              mountPath: /etc/prometheus/rules
            - name: prometheus-storage
              mountPath: /prometheus/
            - name: thanos-gcs-creds
              mountPath: /etc/secret
              readOnly: false
      volumes:
        - name: prometheus-config
          configMap:
            defaultMode: 420
            name: prometheus-config
        - name: prometheus-config-shared
          emptyDir: {}
        - name: prometheus-rules
          configMap:
            name: prometheus-rules
        - name: prometheus-storage
          emptyDir: {}
        - name: thanos-gcs-creds
          secret:
            secretName: thanos-gcs-creds
---
apiVersion: v1
kind: Service
metadata:
  name: thanos-store-gateway
  namespace: CLUSTER-monitoring
spec:
  selector:
    name: prometheus
  ports:
    - protocol: TCP
      port: 10901
      targetPort: 10901
  clusterIP: None
  type: ClusterIP
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: alertmanager
  namespace: CLUSTER-monitoring
spec:
  replicas: 2
  selector:
    matchLabels:
      name: alertmanager
  template:
    metadata:
      labels:
        name: alertmanager
      annotations:
        prometheus.io/scrape: 'true'
        prometheus.io/port: '9093'
    spec:
      containers:
        - name: alertmanager
          image: thekevjames/o11y-alertmanager:latest
          imagePullPolicy: IfNotPresent
          ports:
          - containerPort: 9093
---
kind: Service
apiVersion: v1
metadata:
  name: alertmanager
  namespace: CLUSTER-monitoring
spec:
  selector:
    name: alertmanager
  ports:
  - protocol: TCP
    port: 9093
    targetPort: 9093
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: grafana
  namespace: CLUSTER-monitoring
spec:
  replicas: 2
  selector:
    matchLabels:
      name: grafana
  template:
    metadata:
      labels:
        name: grafana
      annotations:
        prometheus.io/scrape: 'true'
        prometheus.io/port: '3000'
    spec:
      containers:
        - name: grafana
          image: thekevjames/o11y-grafana:latest
          imagePullPolicy: IfNotPresent
          ports:
            - containerPort: 3000
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /robots.txt
              port: 3000
              scheme: HTTP
            initialDelaySeconds: 10
            periodSeconds: 30
            successThreshold: 1
            timeoutSeconds: 2
          livenessProbe:
            failureThreshold: 3
            initialDelaySeconds: 30
            periodSeconds: 10
            successThreshold: 1
            tcpSocket:
              port: 3000
            timeoutSeconds: 1
---
apiVersion: v1
kind: Service
metadata:
  name: grafana
  namespace: CLUSTER-monitoring
spec:
  selector:
    name: grafana
  ports:
    - protocol: TCP
      port: 3000
      targetPort: 3000
  sessionAffinity: ClientIP
  type: LoadBalancer
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: thanos-store-gateway-longterm
  namespace: CLUSTER-monitoring
spec:
  replicas: 2
  selector:
    matchLabels:
      name: thanos-store-gateway-longterm
  template:
    metadata:
      labels:
        name: thanos-store-gateway-longterm
    spec:
      containers:
        - name: thanos
          image: thanosio/thanos:v0.21.1
          args:
          - 'store'
          - '--log.level=info'
          - '--data-dir=/data'
          - '--objstore.config={type: GCS, config: {bucket: kjames-prometheus-longterm}}'
          - '--index-cache-size=500MB'
          - '--chunk-pool-size=500MB'
          env:
            - name : GOOGLE_APPLICATION_CREDENTIALS
              value: /etc/secret/adc.json
          ports:
          - name: http
            containerPort: 10902
          - name: grpc
            containerPort: 10901
          livenessProbe:
            httpGet:
              port: 10902
              path: /-/healthy
          readinessProbe:
            httpGet:
              port: 10902
              path: /-/ready
          volumeMounts:
            - name: thanos-gcs-creds
              mountPath: /etc/secret
              readOnly: false
      volumes:
        - name: thanos-gcs-creds
          secret:
            secretName: thanos-gcs-creds
---
apiVersion: v1
kind: Service
metadata:
  name: thanos-store-gateway-longterm
  namespace: CLUSTER-monitoring
spec:
  selector:
    name: thanos-store-gateway-longterm
  ports:
    - protocol: TCP
      port: 10901
      targetPort: 10901
  clusterIP: None
  type: ClusterIP
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: thanos-querier
  namespace: CLUSTER-monitoring
spec:
  replicas: 2
  selector:
    matchLabels:
      name: thanos-querier
  template:
    metadata:
      labels:
        name: thanos-querier
    spec:
      containers:
      - name: thanos
        image: thanosio/thanos:v0.21.1
        args:
        - 'query'
        - '--log.level=info'
        - '--query.replica-label=replica'
        - '--store=thanos-store-gateway.appcluster-a-monitoring.svc:10901'
        - '--store=thanos-store-gateway.appcluster-b-monitoring.svc:10901'
        - '--store=thanos-store-gateway.CLUSTER-monitoring.svc:10901'
        - '--store=thanos-store-gateway-longterm.CLUSTER-monitoring.svc:10901'
        - '--store=thanos-ruler.CLUSTER-monitoring.svc:10901'
        ports:
        - name: http
          containerPort: 10902
        - name: grpc
          containerPort: 10901
        livenessProbe:
          httpGet:
            port: http
            path: /-/healthy
        readinessProbe:
          httpGet:
            port: http
            path: /-/ready
---
apiVersion: v1
kind: Service
metadata:
  name: thanos-querier
  namespace: CLUSTER-monitoring
spec:
  selector:
    name: thanos-querier
  ports:
  - protocol: TCP
    port: 9090
    targetPort: 10902
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: thanos-compactor
  namespace: CLUSTER-monitoring
spec:
  # N.B. this is the only system not deployed with multiple replicas in this demo
  # Note that this is intentional -- the Thanos Compactor must be run as a singleton
  # and does not pose a system availability issue if it is not running.
  # See https://thanos.io/tip/thanos/quick-tutorial.md/#compactor
  replicas: 1
  selector:
    matchLabels:
      name: thanos-compactor
  template:
    metadata:
      labels:
        name: thanos-compactor
    spec:
      containers:
        - name: thanos
          image: thanosio/thanos:v0.21.1
          args:
            - 'compact'
            - '--log.level=info'
            - '--data-dir=/data'
            - '--objstore.config={type: GCS, config: {bucket: kjames-prometheus-longterm}}'
            - '--wait'
          env:
            - name: GOOGLE_APPLICATION_CREDENTIALS
              value: /etc/secret/adc.json
          ports:
            - name: http
              containerPort: 10902
          livenessProbe:
            httpGet:
              port: 10902
              path: /-/healthy
          readinessProbe:
            httpGet:
              port: 10902
              path: /-/ready
          volumeMounts:
            - name: thanos-gcs-creds
              mountPath: /etc/secret
              readOnly: false
      volumes:
        - name: thanos-gcs-creds
          secret:
            secretName: thanos-gcs-creds
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: thanos-ruler-rules
  namespace: CLUSTER-monitoring
data:
  prometheus.yaml: |
    groups:
    - name: global prometheus alerts
      rules:
      - alert: Prometheus Replica Down
        annotations:
          message: Prometheus replica in cluster {{$labels.cluster}} has disappeared from Prometheus target discovery.
        # TODO: this doesn't look right
        expr: sum(up{instance=~".*:9090", job="kubernetes-service-endpoints"}) by (job,cluster) < 2
        for: 15s
        labels:
          severity: critical
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: thanos-ruler
  namespace: CLUSTER-monitoring
spec:
  replicas: 2
  selector:
    matchLabels:
      name: thanos-ruler
  template:
    metadata:
      labels:
        name: thanos-ruler
    spec:
      containers:
        - name: thanos
          image: thanosio/thanos:v0.21.1
          args:
            - 'rule'
            - '--log.level=info'
            - '--data-dir=/data'
            - '--eval-interval=15s'
            - '--rule-file=/etc/thanos-ruler/*.yaml'
            - '--alertmanagers.url=http://alertmanager.CLUSTER-monitoring.svc:9093'
            - '--query=thanos-querier.CLUSTER-monitoring.svc:9090'
            - '--objstore.config={type: GCS, config: {bucket: kjames-thanos-ruler}}'
            - '--label=ruler_cluster="$(POD_NAMESPACE)"'
            - '--label=replica="$(POD_NAME)"'
          env:
            - name : GOOGLE_APPLICATION_CREDENTIALS
              value: /etc/secret/adc.json
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: POD_NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
          ports:
            - name: http
              containerPort: 10902
            - name: grpc
              containerPort: 10901
          livenessProbe:
            httpGet:
              port: http
              path: /-/healthy
          readinessProbe:
            httpGet:
              port: http
              path: /-/ready
          volumeMounts:
            - name: config
              mountPath: /etc/thanos-ruler
            - name: thanos-gcs-creds
              mountPath: /etc/secret
              readOnly: false
      volumes:
        - name: config
          configMap:
            name: thanos-ruler-rules
        - name: thanos-gcs-creds
          secret:
            secretName: thanos-gcs-creds
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app: thanos-ruler
  name: thanos-ruler
  namespace: CLUSTER-monitoring
spec:
  selector:
    name: thanos-ruler
  ports:
    - protocol: TCP
      name: grpc
      port: 10901
      targetPort: 10901
    - protocol: TCP
      name: http
      port: 9093
      targetPort: 10902
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: promtail-config
  namespace: CLUSTER-monitoring
data:
  promtail.yaml: |-
    server:
      http_listen_port: 9080
      grpc_listen_port: 0

    positions:
      filename: /tmp/positions.yaml

    clients:
      - url: http://loki.CLUSTER-monitoring.svc:3100/loki/api/v1/push

    scrape_configs:
    - job_name: kubernetes-pods-name
      kubernetes_sd_configs:
      - role: pod
      pipeline_stages: []
      relabel_configs:
      - source_labels:
        - __meta_kubernetes_pod_label_name
        target_label: __service__
      - source_labels:
        - __meta_kubernetes_pod_node_name
        target_label: __host__
      - action: drop
        regex: '^$'
        source_labels:
        - __service__
      - action: replace
        replacement: '$1'
        separator: '/'
        source_labels:
        - __meta_kubernetes_namespace
        - __service__
        target_label: job
      - action: replace
        source_labels:
        - __meta_kubernetes_namespace
        target_label: namespace
      - action: replace
        source_labels:
        - __meta_kubernetes_pod_name
        target_label: instance
      - action: replace
        source_labels:
        - __meta_kubernetes_pod_container_name
        target_label: container_name
      - replacement: '/var/log/pods/*$1/*.log'
        separator: '/'
        source_labels:
        - __meta_kubernetes_pod_uid
        - __meta_kubernetes_pod_container_name
        target_label: __path__
    - job_name: kubernetes-pods-app
      kubernetes_sd_configs:
      - role: pod
      pipeline_stages: []
      relabel_configs:
      - action: drop
        regex: '.+'
        source_labels:
        - __meta_kubernetes_pod_label_name
      - source_labels:
        - __meta_kubernetes_pod_label_app
        target_label: __service__
      - source_labels:
        - __meta_kubernetes_pod_node_name
        target_label: __host__
      - action: drop
        regex: '^$'
        source_labels:
        - __service__
      - action: replace
        replacement: '$1'
        separator: '/'
        source_labels:
        - __meta_kubernetes_namespace
        - __service__
        target_label: job
      - action: replace
        source_labels:
        - __meta_kubernetes_namespace
        target_label: namespace
      - action: replace
        source_labels:
        - __meta_kubernetes_pod_name
        target_label: instance
      - action: replace
        source_labels:
        - __meta_kubernetes_pod_container_name
        target_label: container_name
      - replacement: '/var/log/pods/*$1/*.log'
        separator: '/'
        source_labels:
        - __meta_kubernetes_pod_uid
        - __meta_kubernetes_pod_container_name
        target_label: __path__
    - job_name: kubernetes-pods-direct-controllers
      kubernetes_sd_configs:
      - role: pod
      pipeline_stages: []
      relabel_configs:
      - action: drop
        regex: '.+'
        separator: ''
        source_labels:
        - __meta_kubernetes_pod_label_name
        - __meta_kubernetes_pod_label_app
      - action: drop
        regex: '^([0-9a-z-.]+)(-[0-9a-f]{8,10})$'
        source_labels:
        - __meta_kubernetes_pod_controller_name
      - source_labels:
        - __meta_kubernetes_pod_controller_name
        target_label: __service__
      - source_labels:
        - __meta_kubernetes_pod_node_name
        target_label: __host__
      - action: drop
        regex: '^$'
        source_labels:
        - __service__
      - action: replace
        replacement: '$1'
        separator: /
        source_labels:
        - __meta_kubernetes_namespace
        - __service__
        target_label: job
      - action: replace
        source_labels:
        - __meta_kubernetes_namespace
        target_label: namespace
      - action: replace
        source_labels:
        - __meta_kubernetes_pod_name
        target_label: instance
      - action: replace
        source_labels:
        - __meta_kubernetes_pod_container_name
        target_label: container_name
      - replacement: '/var/log/pods/*$1/*.log'
        separator: /
        source_labels:
        - __meta_kubernetes_pod_uid
        - __meta_kubernetes_pod_container_name
        target_label: __path__
    - job_name: kubernetes-pods-indirect-controller
      kubernetes_sd_configs:
      - role: pod
      pipeline_stages: []
      relabel_configs:
      - action: drop
        regex: '.+'
        separator: ''
        source_labels:
        - __meta_kubernetes_pod_label_name
        - __meta_kubernetes_pod_label_app
      - action: keep
        regex: '^([0-9a-z-.]+)(-[0-9a-f]{8,10})$'
        source_labels:
        - __meta_kubernetes_pod_controller_name
      - action: replace
        regex: '^([0-9a-z-.]+)(-[0-9a-f]{8,10})$'
        source_labels:
        - __meta_kubernetes_pod_controller_name
        target_label: __service__
      - source_labels:
        - __meta_kubernetes_pod_node_name
        target_label: __host__
      - action: drop
        regex: '^$'
        source_labels:
        - __service__
      - action: replace
        replacement: '$1'
        separator: '/'
        source_labels:
        - __meta_kubernetes_namespace
        - __service__
        target_label: job
      - action: replace
        source_labels:
        - __meta_kubernetes_namespace
        target_label: namespace
      - action: replace
        source_labels:
        - __meta_kubernetes_pod_name
        target_label: instance
      - action: replace
        source_labels:
        - __meta_kubernetes_pod_container_name
        target_label: container_name
      - replacement: '/var/log/pods/*$1/*.log'
        separator: '/'
        source_labels:
        - __meta_kubernetes_pod_uid
        - __meta_kubernetes_pod_container_name
        target_label: __path__
    - job_name: kubernetes-pods-static
      kubernetes_sd_configs:
      - role: pod
      pipeline_stages: []
      relabel_configs:
      - action: drop
        regex: '^$'
        source_labels:
        - __meta_kubernetes_pod_annotation_kubernetes_io_config_mirror
      - action: replace
        source_labels:
        - __meta_kubernetes_pod_label_component
        target_label: __service__
      - source_labels:
        - __meta_kubernetes_pod_node_name
        target_label: __host__
      - action: drop
        regex: '^$'
        source_labels:
        - __service__
      - action: replace
        replacement: '$1'
        separator: '/'
        source_labels:
        - __meta_kubernetes_namespace
        - __service__
        target_label: job
      - action: replace
        source_labels:
        - __meta_kubernetes_namespace
        target_label: namespace
      - action: replace
        source_labels:
        - __meta_kubernetes_pod_name
        target_label: instance
      - action: replace
        source_labels:
        - __meta_kubernetes_pod_container_name
        target_label: container_name
      - replacement: '/var/log/pods/*$1/*.log'
        separator: '/'
        source_labels:
        - __meta_kubernetes_pod_annotation_kubernetes_io_config_mirror
        - __meta_kubernetes_pod_container_name
        target_label: __path__
---
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: promtail
  namespace: CLUSTER-monitoring
spec:
  selector:
    matchLabels:
      name: promtail
  template:
    metadata:
      labels:
        name: promtail
    spec:
      containers:
        - name: promtail
          image: grafana/promtail:2.2.1
          args:
          - '-config.file=/etc/promtail/promtail.yaml'
          env:
          - name: HOSTNAME
            valueFrom:
              fieldRef:
                fieldPath: spec.nodeName
          readinessProbe:
            httpGet:
              path: /ready
              port: http
              scheme: HTTP
            initialDelaySeconds: 10
          ports:
            - name: http
              containerPort: 80
          securityContext:
            privileged: true
            runAsUser: 0
          volumeMounts:
          - name: config
            mountPath: /etc/promtail
          - name: logs-docker
            mountPath: /var/lib/docker/containers
            readOnly: true
          - name: logs-varlog
            mountPath: /var/log
      volumes:
      - name: config
        configMap:
          name: promtail-config
      - name: logs-varlog
        hostPath:
          path: /var/log
      - name: logs-docker
        hostPath:
          path: /var/lib/docker/containers
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: loki-config
  namespace: CLUSTER-monitoring
data:
  # TODO: split this apart a bit (defaults to all features enabled). Need to split compactor, at least,
  # since it's supposed to be a singleton
  loki.yaml: |-
    auth_enabled: false

    server:
      http_listen_port: 3100
      grpc_listen_port: 9096

    ingester:
      wal:
        enabled: true
        dir: /tmp/wal
      lifecycler:
        address: 127.0.0.1
        ring:
          kvstore:
            store: inmemory
          replication_factor: 1
        final_sleep: 0s
      # N.B. as for prometheus & thanos, these are artifically low for demo purposes
      chunk_idle_period: 10m
      max_chunk_age: 10m
      chunk_target_size: 1048576
      chunk_retain_period: 30s
      max_transfer_retries: 0

    schema_config:
      configs:
        - from: 2000-01-01
          store: boltdb-shipper
          object_store: gcs
          schema: v11
          index:
            prefix: index_
            period: 24h

    storage_config:
      boltdb_shipper:
        active_index_directory: /tmp/loki/index
        shared_store: gcs
        cache_location: /tmp/loki/boltdb-cache
      gcs:
        bucket_name: kjames-loki

    compactor:
      working_directory: /tmp/loki/compactor
      shared_store: filesystem
      compaction_interval: 5m

    limits_config:
      reject_old_samples: true
      reject_old_samples_max_age: 168h

    chunk_store_config:
      max_look_back_period: 0s

    table_manager:
      retention_deletes_enabled: false
      retention_period: 0s

    ruler:
      storage:
        type: local
        local:
          directory: /tmp/loki/rules
      rule_path: /tmp/loki/rules-temp
      alertmanager_url: http://alertmanager.CLUSTER-monitoring.svc:9093
      ring:
        kvstore:
          store: inmemory
      enable_api: true
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: loki
  namespace: CLUSTER-monitoring
spec:
  replicas: 2
  selector:
    matchLabels:
      name: loki
  template:
    metadata:
      labels:
        name: loki
    spec:
      containers:
        - name: loki
          image: grafana/loki:2.2.1
          args:
          - '-config.file=/etc/loki/loki.yaml'
          env:
            - name: GOOGLE_APPLICATION_CREDENTIALS
              value: /etc/secret/adc.json
          ports:
            - name: http
              containerPort: 3100
            - name: grpc
              containerPort: 9096
          # TODO: liveness and readiness probes
          volumeMounts:
            # TODO: pvc for ingestor storage
            - name: config
              mountPath: /etc/loki
            - name: thanos-gcs-creds
              mountPath: /etc/secret
              readOnly: false
      volumes:
        - name: config
          configMap:
            name: loki-config
        - name: thanos-gcs-creds  # TODO: rename
          secret:
            secretName: thanos-gcs-creds
---
apiVersion: v1
kind: Service
metadata:
  name: loki
  namespace: CLUSTER-monitoring
spec:
  selector:
    name: loki
  ports:
    - protocol: TCP
      port: 3100
      targetPort: 3100
  clusterIP: None
  type: ClusterIP
