---
apiVersion: v1
kind: Namespace
metadata:
  name: CLUSTER-monitoring
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-config
  namespace: CLUSTER-monitoring
data:
  prometheus.yaml.tmpl: |-
    global:
      scrape_interval: 60s
      evaluation_interval: 5s
      external_labels:
        # N.B. see notes on namespace as cluster emulation
        cluster: $(POD_NAMESPACE)
        replica: $(POD_NAME)

    rule_files:
      - /etc/prometheus/rules/*.yaml

    alerting:
      alert_relabel_configs:
      - regex: replica
        action: labeldrop

      alertmanagers:
      - scheme: http
        static_configs:
        - targets:
          - "alertmanager.CLUSTER-monitoring.svc:9093"

    scrape_configs:
      - job_name: 'kubernetes-apiservers'
        kubernetes_sd_configs:
        - role: endpoints
        scheme: https
        tls_config:
          ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
        relabel_configs:
        - source_labels: [__meta_kubernetes_namespace, __meta_kubernetes_service_name, __meta_kubernetes_endpoint_port_name]
          action: keep
          regex: default;kubernetes;https

      - job_name: 'kubernetes-nodes'
        kubernetes_sd_configs:
        - role: node
        scheme: https
        tls_config:
          ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
        relabel_configs:
        - action: labelmap
          regex: __meta_kubernetes_node_label_(.+)
        - target_label: __address__
          replacement: kubernetes.default.svc:443
        - source_labels: [__meta_kubernetes_node_name]
          regex: (.+)
          target_label: __metrics_path__
          replacement: /api/v1/nodes/${1}/proxy/metrics

      - job_name: 'kubernetes-pods'
        kubernetes_sd_configs:
        - role: pod
        relabel_configs:
        - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
          action: keep
          regex: true
        - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
          action: replace
          target_label: __metrics_path__
          regex: (.+)
        - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]
          action: replace
          regex: ([^:]+)(?::\d+)?;(\d+)
          replacement: $1:$2
          target_label: __address__
        - action: labelmap
          regex: __meta_kubernetes_pod_label_(.+)
        - source_labels: [__meta_kubernetes_namespace]
          action: replace
          target_label: kubernetes_namespace
        - source_labels: [__meta_kubernetes_pod_name]
          action: replace
          target_label: kubernetes_pod_name

      - job_name: 'kubernetes-cadvisor'
        scheme: https
        tls_config:
          ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
        kubernetes_sd_configs:
        - role: node
        relabel_configs:
        - action: labelmap
          regex: __meta_kubernetes_node_label_(.+)
        - target_label: __address__
          replacement: kubernetes.default.svc:443
        - source_labels: [__meta_kubernetes_node_name]
          regex: (.+)
          target_label: __metrics_path__
          replacement: /api/v1/nodes/${1}/proxy/metrics/cadvisor

      - job_name: 'kubernetes-service-endpoints'
        kubernetes_sd_configs:
        - role: endpoints
        relabel_configs:
        - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scrape]
          action: keep
          regex: true
        - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scheme]
          action: replace
          target_label: __scheme__
          regex: (https?)
        - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_path]
          action: replace
          target_label: __metrics_path__
          regex: (.+)
        - source_labels: [__address__, __meta_kubernetes_service_annotation_prometheus_io_port]
          action: replace
          target_label: __address__
          regex: ([^:]+)(?::\d+)?;(\d+)
          replacement: $1:$2
        - action: labelmap
          regex: __meta_kubernetes_service_label_(.+)
        - source_labels: [__meta_kubernetes_namespace]
          action: replace
          target_label: kubernetes_namespace
        - source_labels: [__meta_kubernetes_service_name]
          action: replace
          target_label: kubernetes_name
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-rules
  labels:
    name: prometheus-rules
  namespace: CLUSTER-monitoring
data:
  ruler-alerts.yaml: |-
    groups:
    - name: ruler alerts
      rules:
      - alert: thanos-rule Query DNS Failures
        annotations:
          description: Thanos Rule {{$labels.job}} has {{$value | humanize}}% of failing DNS queries for query endpoints.
          runbook_url: https://github.com/thanos-io/thanos/tree/main/mixin/runbook.md#alert-name-thanosrulequeryhighdnsfailures
          summary: Thanos Rule is having high number of DNS failures.
        expr: |
          (
            sum by (job, instance) (rate(thanos_rule_query_apis_dns_failures_total{job=~".*thanos-rule.*"}[5m]))
          /
            sum by (job, instance) (rate(thanos_rule_query_apis_dns_lookups_total{job=~".*thanos-rule.*"}[5m]))
          * 100 > 1
          )
        for: 15m
        labels:
          severity: warning
      - alert: thanos-rule Alertmanager DNS Failures
        annotations:
          description: Thanos Rule {{$labels.instance}} has {{$value | humanize}}% of failing DNS queries for Alertmanager endpoints.
          runbook_url: https://github.com/thanos-io/thanos/tree/main/mixin/runbook.md#alert-name-thanosrulealertmanagerhighdnsfailures
          summary: Thanos Rule is having high number of DNS failures.
        expr: |
          (
            sum by (job, instance) (rate(thanos_rule_alertmanagers_dns_failures_total{job=~".*thanos-rule.*"}[5m]))
          /
            sum by (job, instance) (rate(thanos_rule_alertmanagers_dns_lookups_total{job=~".*thanos-rule.*"}[5m]))
          * 100 > 1
          )
        for: 15m
        labels:
          severity: warning
      - alert: thanos-rule No Rule Evaluations
        annotations:
          description: Thanos Rule {{$labels.instance}} did not perform any rule evaluations in the past 10 minutes.
          runbook_url: https://github.com/thanos-io/thanos/tree/main/mixin/runbook.md#alert-name-thanosnoruleevaluations
          summary: Thanos Rule did not perform any rule evaluations.
        expr: |
          sum by (job, instance) (rate(prometheus_rule_evaluations_total{job=~".*thanos-rule.*"}[5m])) <= 0
            and
          sum by (job, instance) (thanos_rule_loaded_rules{job=~".*thanos-rule.*"}) > 0
        for: 5m
        labels:
          severity: critical
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: prometheus
  namespace: CLUSTER-monitoring
spec:
  replicas: 2
  selector:
    matchLabels:
      name: prometheus
  template:
    metadata:
      labels:
        name: prometheus
      annotations:
        prometheus.io/scrape: 'true'
        prometheus.io/port: '9090'
    spec:
      containers:
        - name: prometheus
          image: prom/prometheus:v2.27.1
          imagePullPolicy: IfNotPresent
          args:
            - '--config.file=/etc/prometheus-shared/prometheus.yaml'
            - '--storage.tsdb.path=/prometheus/'
            - '--web.enable-lifecycle'
            - '--storage.tsdb.no-lockfile'
            # N.B. this should almost certainly be higher in production (Thanos recommends 2h).
            # I have it set low here only for demo purposes.
            - '--storage.tsdb.min-block-duration=10m'
            - '--storage.tsdb.max-block-duration=10m'
            # N.B. this should be "not less than 3x the block size"
            - '--storage.tsdb.retention.time=1h'
          ports:
            - containerPort: 9090
          volumeMounts:
            - name: prometheus-config-shared
              mountPath: /etc/prometheus-shared/
            - name: prometheus-rules
              mountPath: /etc/prometheus/rules
            - name: prometheus-storage
              mountPath: /prometheus/
        - name: thanos
          image: thanosio/thanos:v0.21.1
          args:
            - 'sidecar'
            - '--log.level=info'
            - '--tsdb.path=/prometheus/'
            - '--prometheus.url=http://127.0.0.1:9090'
            - '--objstore.config={type: GCS, config: {bucket: kjames-prometheus-longterm}}'
            - '--reloader.config-file=/etc/prometheus/prometheus.yaml.tmpl'
            - '--reloader.config-envsubst-file=/etc/prometheus-shared/prometheus.yaml'
            - '--reloader.rule-dir=/etc/prometheus/rules/'
          env:
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: POD_NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            - name: GOOGLE_APPLICATION_CREDENTIALS
              value: /etc/secret/adc.json
          ports:
            - name: http-sidecar
              containerPort: 10902
            - name: grpc
              containerPort: 10901
          livenessProbe:
            httpGet:
              port: 10902
              path: /-/healthy
          readinessProbe:
            httpGet:
              port: 10902
              path: /-/ready
          volumeMounts:
            - name: prometheus-config
              mountPath: /etc/prometheus
            - name: prometheus-config-shared
              mountPath: /etc/prometheus-shared/
            - name: prometheus-rules
              mountPath: /etc/prometheus/rules
            - name: prometheus-storage
              mountPath: /prometheus/
            - name: thanos-gcs-creds
              mountPath: /etc/secret
              readOnly: false
      volumes:
        - name: prometheus-config
          configMap:
            defaultMode: 420
            name: prometheus-config
        - name: prometheus-config-shared
          emptyDir: {}
        - name: prometheus-rules
          configMap:
            name: prometheus-rules
        - name: prometheus-storage
          emptyDir: {}
        - name: thanos-gcs-creds
          secret:
            secretName: thanos-gcs-creds
---
apiVersion: v1
kind: Service
metadata:
  name: thanos-store-gateway
  namespace: CLUSTER-monitoring
spec:
  selector:
    name: prometheus
  ports:
    - protocol: TCP
      port: 10901
      targetPort: 10901
  clusterIP: None
  type: ClusterIP
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: alertmanager-config
  namespace: CLUSTER-monitoring
data:
  alertmanager.yml: |-
    global:
      resolve_timeout: 5m

    route:
      group_by: ['alertname', 'cluster']
      group_wait: 10s
      group_interval: 10s
      repeat_interval: 1h
      receiver: 'webhook.site'

    receivers:
      - name: 'webhook.site'
        webhook_configs:
        # https://webhook.site/#!/b46fe156-506d-4376-9050-93694845380b
        - url: 'https://webhook.site/b46fe156-506d-4376-9050-93694845380b'
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: alertmanager
  namespace: CLUSTER-monitoring
spec:
  replicas: 2
  selector:
    matchLabels:
      name: alertmanager
  template:
    metadata:
      labels:
        name: alertmanager
      annotations:
        prometheus.io/scrape: 'true'
        prometheus.io/port: '9093'
    spec:
      containers:
        - name: alertmanager
          image: prom/alertmanager:v0.22.2
          imagePullPolicy: IfNotPresent
          ports:
          - containerPort: 9093
          volumeMounts:
          - name: config
            mountPath: /etc/alertmanager
      volumes:
      - name: config
        configMap:
          name: alertmanager-config
---
kind: Service
apiVersion: v1
metadata:
  name: alertmanager
  namespace: CLUSTER-monitoring
spec:
  selector:
    name: alertmanager
  ports:
  - protocol: TCP
    port: 9093
    targetPort: 9093
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: grafana-config
  namespace: CLUSTER-monitoring
data:
  grafana.ini: |-
    [server]
    http_port = 3000
    ;domain = localhost
    ;enforce_domain = false
    ;root_url = http://localhost:3000
    enable_gzip = true

    [session]
    provider = memory

    [analytics]
    reporting_enabled = false
    check_for_updates = false

    [security]
    ;admin_user = admin
    ;admin_password = admin

    [snapshots]
    external_enabled = false

    [users]
    allow_sign_up = false
    allow_org_create = false
    auto_assign_org = true
    auto_assign_org_role = Viewer

    default_theme = dark

    [auth]
    ;disable_login_form = true
    ;disable_signout_menu = false

    #################################### Anonymous Auth ##########################
    [auth.anonymous]
    ;enabled = false
    ;org_name = Main Org.
    ;org_role = Viewer

    #################################### Github Auth ##########################
    [auth.github]
    ;enabled = false
    ;allow_sign_up = true
    ;client_id = some_id
    ;client_secret = some_secret
    ;scopes = user:email,read:org
    ;auth_url = https://github.com/login/oauth/authorize
    ;token_url = https://github.com/login/oauth/access_token
    ;api_url = https://api.github.com/user
    ;team_ids =
    ;allowed_organizations =

    #################################### Google Auth ##########################
    [auth.google]
    ;enabled = false
    ;allow_sign_up = true
    ;client_id = some_client_id
    ;client_secret = some_client_secret
    ;scopes = https://www.googleapis.com/auth/userinfo.profile https://www.googleapis.com/auth/userinfo.email
    ;auth_url = https://accounts.google.com/o/oauth2/auth
    ;token_url = https://accounts.google.com/o/oauth2/token
    ;api_url = https://www.googleapis.com/oauth2/v1/userinfo
    ;allowed_domains =

    #################################### Generic OAuth ##########################
    [auth.generic_oauth]
    ;enabled = false
    ;name = OAuth
    ;allow_sign_up = true
    ;client_id = some_id
    ;client_secret = some_secret
    ;scopes = user:email,read:org
    ;auth_url = https://foo.bar/login/oauth/authorize
    ;token_url = https://foo.bar/login/oauth/access_token
    ;api_url = https://foo.bar/user
    ;team_ids =
    ;allowed_organizations =

    #################################### Grafana.com Auth ####################
    [auth.grafana_com]
    ;enabled = false
    ;allow_sign_up = true
    ;client_id = some_id
    ;client_secret = some_secret
    ;scopes = user:email
    ;allowed_organizations =

    #################################### Auth Proxy ##########################
    [auth.proxy]
    ;enabled = false
    ;header_name = X-WEBAUTH-USER
    ;header_property = username
    ;auto_sign_up = true
    ;ldap_sync_ttl = 60
    ;whitelist = 192.168.1.1, 192.168.2.1

    #################################### Basic Auth ##########################
    [auth.basic]
    ;enabled = true

    #################################### Auth LDAP ##########################
    [auth.ldap]
    ;enabled = false
    ;config_file = /etc/grafana/ldap.toml
    ;allow_sign_up = true

    #################################### Logging ##########################
    [log]
    mode = console
    ;level = info

    [log.console]
    ;level =
    ;format = console

    #################################### Dashboard JSON files ##########################
    [dashboards.json]
    enabled = true
    path = /var/lib/grafana/dashboards

    #################################### Alerting ############################
    [alerting]
    enabled = true
    execute_alerts = false

    #################################### Internal Grafana Metrics ##########################
    [metrics]
    ;enabled = true
    ;interval_seconds  = 10

    #################################### Grafana.com integration  ##########################
    [grafana_com]
    ;url = https://grafana.com

    #################################### Feature Toggles  ##########################
    [feature_toggles]
    enable = ngalert
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: grafana-dashboards
  namespace: CLUSTER-monitoring
data:
  app.json: |-
    {
      "annotations": {
        "list": [
          {
            "builtIn": 1,
            "datasource": "-- Grafana --",
            "enable": true,
            "hide": true,
            "iconColor": "rgba(0, 211, 255, 1)",
            "name": "Annotations & Alerts",
            "type": "dashboard"
          }
        ]
      },
      "editable": true,
      "gnetId": null,
      "graphTooltip": 0,
      "links": [],
      "panels": [
        {
          "aliasColors": {},
          "bars": false,
          "dashLength": 10,
          "dashes": false,
          "datasource": "thanos-querier",
          "fieldConfig": {
            "defaults": {},
            "overrides": []
          },
          "fill": 1,
          "fillGradient": 0,
          "gridPos": {
            "h": 8,
            "w": 12,
            "x": 0,
            "y": 0
          },
          "hiddenSeries": false,
          "id": 2,
          "legend": {
            "avg": false,
            "current": false,
            "max": false,
            "min": false,
            "show": true,
            "total": false,
            "values": false
          },
          "lines": true,
          "linewidth": 1,
          "nullPointMode": "null",
          "options": {
            "alertThreshold": true
          },
          "percentage": false,
          "pluginVersion": "7.5.7",
          "pointradius": 2,
          "points": false,
          "renderer": "flot",
          "seriesOverrides": [],
          "spaceLength": 10,
          "stack": false,
          "steppedLine": false,
          "targets": [
            {
              "exemplar": true,
              "expr": "max by (kubernetes_pod_name) (system_in_flight_total)",
              "interval": "",
              "legendFormat": "",
              "queryType": "randomWalk",
              "refId": "A"
            }
          ],
          "thresholds": [],
          "timeFrom": null,
          "timeRegions": [],
          "timeShift": null,
          "title": "Job Concurrency",
          "tooltip": {
            "shared": true,
            "sort": 0,
            "value_type": "individual"
          },
          "type": "graph",
          "xaxis": {
            "buckets": null,
            "mode": "time",
            "name": null,
            "show": true,
            "values": []
          },
          "yaxes": [
            {
              "format": "short",
              "label": null,
              "logBase": 1,
              "max": null,
              "min": null,
              "show": true
            },
            {
              "format": "short",
              "label": null,
              "logBase": 1,
              "max": null,
              "min": null,
              "show": true
            }
          ],
          "yaxis": {
            "align": false,
            "alignLevel": null
          }
        },
        {
          "aliasColors": {},
          "bars": false,
          "dashLength": 10,
          "dashes": false,
          "datasource": "thanos-querier",
          "fieldConfig": {
            "defaults": {},
            "overrides": []
          },
          "fill": 1,
          "fillGradient": 0,
          "gridPos": {
            "h": 8,
            "w": 12,
            "x": 12,
            "y": 0
          },
          "hiddenSeries": false,
          "id": 6,
          "legend": {
            "avg": false,
            "current": false,
            "max": false,
            "min": false,
            "show": true,
            "total": false,
            "values": false
          },
          "lines": true,
          "linewidth": 1,
          "nullPointMode": "null",
          "options": {
            "alertThreshold": true
          },
          "percentage": false,
          "pluginVersion": "7.5.7",
          "pointradius": 2,
          "points": false,
          "renderer": "flot",
          "seriesOverrides": [],
          "spaceLength": 10,
          "stack": false,
          "steppedLine": false,
          "targets": [
            {
              "exemplar": true,
              "expr": "histogram_quantile(0.90, sum by (stage, le) (rate(job_latency_seconds_bucket[5m])))",
              "interval": "",
              "legendFormat": "",
              "queryType": "randomWalk",
              "refId": "A"
            }
          ],
          "thresholds": [],
          "timeFrom": null,
          "timeRegions": [],
          "timeShift": null,
          "title": "Job Latency",
          "tooltip": {
            "shared": true,
            "sort": 0,
            "value_type": "individual"
          },
          "type": "graph",
          "xaxis": {
            "buckets": null,
            "mode": "time",
            "name": null,
            "show": true,
            "values": []
          },
          "yaxes": [
            {
              "format": "short",
              "label": null,
              "logBase": 1,
              "max": null,
              "min": null,
              "show": true
            },
            {
              "format": "short",
              "label": null,
              "logBase": 1,
              "max": null,
              "min": null,
              "show": true
            }
          ],
          "yaxis": {
            "align": false,
            "alignLevel": null
          }
        },
        {
          "aliasColors": {},
          "bars": false,
          "dashLength": 10,
          "dashes": false,
          "datasource": "thanos-querier",
          "fieldConfig": {
            "defaults": {},
            "overrides": []
          },
          "fill": 1,
          "fillGradient": 0,
          "gridPos": {
            "h": 8,
            "w": 12,
            "x": 0,
            "y": 8
          },
          "hiddenSeries": false,
          "id": 4,
          "legend": {
            "avg": false,
            "current": false,
            "max": false,
            "min": false,
            "show": true,
            "total": false,
            "values": false
          },
          "lines": true,
          "linewidth": 1,
          "nullPointMode": "null",
          "options": {
            "alertThreshold": true
          },
          "percentage": false,
          "pluginVersion": "7.5.7",
          "pointradius": 2,
          "points": false,
          "renderer": "flot",
          "seriesOverrides": [],
          "spaceLength": 10,
          "stack": false,
          "steppedLine": false,
          "targets": [
            {
              "exemplar": true,
              "expr": "sum(rate(job_failures_total[5m])) / sum(rate(job_latency_seconds_count[5m]))",
              "interval": "",
              "legendFormat": "",
              "queryType": "randomWalk",
              "refId": "A"
            }
          ],
          "thresholds": [],
          "timeFrom": null,
          "timeRegions": [],
          "timeShift": null,
          "title": "Error Rate",
          "tooltip": {
            "shared": true,
            "sort": 0,
            "value_type": "individual"
          },
          "type": "graph",
          "xaxis": {
            "buckets": null,
            "mode": "time",
            "name": null,
            "show": true,
            "values": []
          },
          "yaxes": [
            {
              "format": "short",
              "label": null,
              "logBase": 1,
              "max": null,
              "min": null,
              "show": true
            },
            {
              "format": "short",
              "label": null,
              "logBase": 1,
              "max": null,
              "min": null,
              "show": true
            }
          ],
          "yaxis": {
            "align": false,
            "alignLevel": null
          }
        }
      ],
      "schemaVersion": 27,
      "style": "dark",
      "tags": [],
      "time": {
        "from": "now-6h",
        "to": "now"
      },
      "timepicker": {},
      "timezone": "",
      "title": "App",
      "uid": "9tVG70eMz",
      "version": 1
    }
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: grafana-provisioning-dashboards
  namespace: CLUSTER-monitoring
data:
  default.yaml: |-
    apiVersion: 1
    providers:
      - name: preload
        type: file
        disableDeletion: true
        updateIntervalSeconds: 10
        allowUiUpdates: false
        options:
          path: /var/lib/grafana/dashboards
          foldersFromFilesStructure: true
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: grafana-provisioning-datasources
  namespace: CLUSTER-monitoring
data:
  loki.yaml: |-
    apiVersion: 1
    datasources:
      - name: loki
        type: loki
        access: proxy
        uid: loki
        url: "http://loki:3100"
        version: 1
  prometheus.yaml: |-
    apiVersion: 1
    datasources:
      - name: thanos-querier
        type: prometheus
        access: proxy
        uid: thanos-querier
        url: "http://thanos-querier:9090"
        version: 1
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: grafana
  namespace: CLUSTER-monitoring
spec:
  replicas: 2
  selector:
    matchLabels:
      name: grafana
  template:
    metadata:
      labels:
        name: grafana
      annotations:
        prometheus.io/scrape: 'true'
        prometheus.io/port: '3000'
    spec:
      containers:
        - name: grafana
          image: grafana/grafana:8.0.1
          imagePullPolicy: IfNotPresent
          ports:
            - containerPort: 3000
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /robots.txt
              port: 3000
              scheme: HTTP
            initialDelaySeconds: 10
            periodSeconds: 30
            successThreshold: 1
            timeoutSeconds: 2
          livenessProbe:
            failureThreshold: 3
            initialDelaySeconds: 30
            periodSeconds: 10
            successThreshold: 1
            tcpSocket:
              port: 3000
            timeoutSeconds: 1
          volumeMounts:
          - name: config
            mountPath: /etc/grafana
          - name: dashboards
            mountPath: /var/lib/grafana/dashboards
          - name: provisioning-dashboards
            mountPath: /etc/grafana/provisioning/dashboards
          - name: provisioning-datasources
            mountPath: /etc/grafana/provisioning/datasources
      volumes:
      - name: config
        configMap:
          name: grafana-config
      - name: dashboards
        configMap:
          name: grafana-dashboards
      - name: provisioning-dashboards
        configMap:
          name: grafana-provisioning-dashboards
      - name: provisioning-datasources
        configMap:
          name: grafana-provisioning-datasources
---
apiVersion: v1
kind: Service
metadata:
  name: grafana
  namespace: CLUSTER-monitoring
spec:
  selector:
    name: grafana
  ports:
    - protocol: TCP
      port: 3000
      targetPort: 3000
  sessionAffinity: ClientIP
  type: LoadBalancer
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: thanos-store-gateway-longterm
  namespace: CLUSTER-monitoring
spec:
  replicas: 2
  selector:
    matchLabels:
      name: thanos-store-gateway-longterm
  template:
    metadata:
      labels:
        name: thanos-store-gateway-longterm
    spec:
      containers:
        - name: thanos
          image: thanosio/thanos:v0.21.1
          args:
          - 'store'
          - '--log.level=info'
          - '--data-dir=/data'
          - '--objstore.config={type: GCS, config: {bucket: kjames-prometheus-longterm}}'
          - '--index-cache-size=500MB'
          - '--chunk-pool-size=500MB'
          env:
            - name : GOOGLE_APPLICATION_CREDENTIALS
              value: /etc/secret/adc.json
          ports:
          - name: http
            containerPort: 10902
          - name: grpc
            containerPort: 10901
          livenessProbe:
            httpGet:
              port: 10902
              path: /-/healthy
          readinessProbe:
            httpGet:
              port: 10902
              path: /-/ready
          volumeMounts:
            - name: thanos-gcs-creds
              mountPath: /etc/secret
              readOnly: false
      volumes:
        - name: thanos-gcs-creds
          secret:
            secretName: thanos-gcs-creds
---
apiVersion: v1
kind: Service
metadata:
  name: thanos-store-gateway-longterm
  namespace: CLUSTER-monitoring
spec:
  selector:
    name: thanos-store-gateway-longterm
  ports:
    - protocol: TCP
      port: 10901
      targetPort: 10901
  clusterIP: None
  type: ClusterIP
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: thanos-querier
  namespace: CLUSTER-monitoring
spec:
  replicas: 2
  selector:
    matchLabels:
      name: thanos-querier
  template:
    metadata:
      labels:
        name: thanos-querier
    spec:
      containers:
      - name: thanos
        image: thanosio/thanos:v0.21.1
        args:
        - 'query'
        - '--log.level=info'
        - '--query.replica-label=replica'
        - '--store=thanos-store-gateway.appcluster-a-monitoring.svc:10901'
        - '--store=thanos-store-gateway.appcluster-b-monitoring.svc:10901'
        - '--store=thanos-store-gateway.CLUSTER-monitoring.svc:10901'
        - '--store=thanos-store-gateway-longterm.CLUSTER-monitoring.svc:10901'
        - '--store=thanos-ruler.CLUSTER-monitoring.svc:10901'
        ports:
        - name: http
          containerPort: 10902
        - name: grpc
          containerPort: 10901
        livenessProbe:
          httpGet:
            port: http
            path: /-/healthy
        readinessProbe:
          httpGet:
            port: http
            path: /-/ready
---
apiVersion: v1
kind: Service
metadata:
  name: thanos-querier
  namespace: CLUSTER-monitoring
spec:
  selector:
    name: thanos-querier
  ports:
  - protocol: TCP
    port: 9090
    targetPort: 10902
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: thanos-compactor
  namespace: CLUSTER-monitoring
spec:
  # N.B. this is the only system not deployed with multiple replicas in this demo
  # Note that this is intentional -- the Thanos Compactor must be run as a singleton
  # and does not pose a system availability issue if it is not running.
  # See https://thanos.io/tip/thanos/quick-tutorial.md/#compactor
  replicas: 1
  selector:
    matchLabels:
      name: thanos-compactor
  template:
    metadata:
      labels:
        name: thanos-compactor
    spec:
      containers:
        - name: thanos
          image: thanosio/thanos:v0.21.1
          args:
            - 'compact'
            - '--log.level=info'
            - '--data-dir=/data'
            - '--objstore.config={type: GCS, config: {bucket: kjames-prometheus-longterm}}'
            - '--wait'
          env:
            - name: GOOGLE_APPLICATION_CREDENTIALS
              value: /etc/secret/adc.json
          ports:
            - name: http
              containerPort: 10902
          livenessProbe:
            httpGet:
              port: 10902
              path: /-/healthy
          readinessProbe:
            httpGet:
              port: 10902
              path: /-/ready
          volumeMounts:
            - name: thanos-gcs-creds
              mountPath: /etc/secret
              readOnly: false
      volumes:
        - name: thanos-gcs-creds
          secret:
            secretName: thanos-gcs-creds
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: thanos-ruler-rules
  namespace: CLUSTER-monitoring
data:
  prometheus.yaml: |
    groups:
    - name: global prometheus alerts
      rules:
      - alert: Prometheus Replica Down
        annotations:
          message: Prometheus replica in cluster {{$labels.cluster}} has disappeared from Prometheus target discovery.
        # TODO: this doesn't look right
        expr: sum(up{instance=~".*:9090", job="kubernetes-service-endpoints"}) by (job,cluster) < 2
        for: 15s
        labels:
          severity: critical
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: thanos-ruler
  namespace: CLUSTER-monitoring
spec:
  replicas: 2
  selector:
    matchLabels:
      name: thanos-ruler
  template:
    metadata:
      labels:
        name: thanos-ruler
    spec:
      containers:
        - name: thanos
          image: thanosio/thanos:v0.21.1
          args:
            - 'rule'
            - '--log.level=info'
            - '--data-dir=/data'
            - '--eval-interval=15s'
            - '--rule-file=/etc/thanos-ruler/*.yaml'
            - '--alertmanagers.url=http://alertmanager.CLUSTER-monitoring.svc:9093'
            - '--query=thanos-querier.CLUSTER-monitoring.svc:9090'
            - '--objstore.config={type: GCS, config: {bucket: kjames-thanos-ruler}}'
            - '--label=ruler_cluster="$(POD_NAMESPACE)"'
            - '--label=replica="$(POD_NAME)"'
          env:
            - name : GOOGLE_APPLICATION_CREDENTIALS
              value: /etc/secret/adc.json
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: POD_NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
          ports:
            - name: http
              containerPort: 10902
            - name: grpc
              containerPort: 10901
          livenessProbe:
            httpGet:
              port: http
              path: /-/healthy
          readinessProbe:
            httpGet:
              port: http
              path: /-/ready
          volumeMounts:
            - name: config
              mountPath: /etc/thanos-ruler
            - name: thanos-gcs-creds
              mountPath: /etc/secret
              readOnly: false
      volumes:
        - name: config
          configMap:
            name: thanos-ruler-rules
        - name: thanos-gcs-creds
          secret:
            secretName: thanos-gcs-creds
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app: thanos-ruler
  name: thanos-ruler
  namespace: CLUSTER-monitoring
spec:
  selector:
    name: thanos-ruler
  ports:
    - protocol: TCP
      name: grpc
      port: 10901
      targetPort: 10901
    - protocol: TCP
      name: http
      port: 9093
      targetPort: 10902
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: promtail-config
  namespace: CLUSTER-monitoring
data:
  promtail.yaml: |-
    server:
      http_listen_port: 9080
      grpc_listen_port: 0

    positions:
      filename: /tmp/positions.yaml

    clients:
      - url: http://loki.CLUSTER-monitoring.svc:3100/loki/api/v1/push

    scrape_configs:
    - job_name: kubernetes-pods-name
      kubernetes_sd_configs:
      - role: pod
      pipeline_stages: []
      relabel_configs:
      - source_labels:
        - __meta_kubernetes_pod_label_name
        target_label: __service__
      - source_labels:
        - __meta_kubernetes_pod_node_name
        target_label: __host__
      - action: drop
        regex: '^$'
        source_labels:
        - __service__
      - action: replace
        replacement: '$1'
        separator: '/'
        source_labels:
        - __meta_kubernetes_namespace
        - __service__
        target_label: job
      - action: replace
        source_labels:
        - __meta_kubernetes_namespace
        target_label: namespace
      - action: replace
        source_labels:
        - __meta_kubernetes_pod_name
        target_label: instance
      - action: replace
        source_labels:
        - __meta_kubernetes_pod_container_name
        target_label: container_name
      - replacement: '/var/log/pods/*$1/*.log'
        separator: '/'
        source_labels:
        - __meta_kubernetes_pod_uid
        - __meta_kubernetes_pod_container_name
        target_label: __path__
    - job_name: kubernetes-pods-app
      kubernetes_sd_configs:
      - role: pod
      pipeline_stages: []
      relabel_configs:
      - action: drop
        regex: '.+'
        source_labels:
        - __meta_kubernetes_pod_label_name
      - source_labels:
        - __meta_kubernetes_pod_label_app
        target_label: __service__
      - source_labels:
        - __meta_kubernetes_pod_node_name
        target_label: __host__
      - action: drop
        regex: '^$'
        source_labels:
        - __service__
      - action: replace
        replacement: '$1'
        separator: '/'
        source_labels:
        - __meta_kubernetes_namespace
        - __service__
        target_label: job
      - action: replace
        source_labels:
        - __meta_kubernetes_namespace
        target_label: namespace
      - action: replace
        source_labels:
        - __meta_kubernetes_pod_name
        target_label: instance
      - action: replace
        source_labels:
        - __meta_kubernetes_pod_container_name
        target_label: container_name
      - replacement: '/var/log/pods/*$1/*.log'
        separator: '/'
        source_labels:
        - __meta_kubernetes_pod_uid
        - __meta_kubernetes_pod_container_name
        target_label: __path__
    - job_name: kubernetes-pods-direct-controllers
      kubernetes_sd_configs:
      - role: pod
      pipeline_stages: []
      relabel_configs:
      - action: drop
        regex: '.+'
        separator: ''
        source_labels:
        - __meta_kubernetes_pod_label_name
        - __meta_kubernetes_pod_label_app
      - action: drop
        regex: '^([0-9a-z-.]+)(-[0-9a-f]{8,10})$'
        source_labels:
        - __meta_kubernetes_pod_controller_name
      - source_labels:
        - __meta_kubernetes_pod_controller_name
        target_label: __service__
      - source_labels:
        - __meta_kubernetes_pod_node_name
        target_label: __host__
      - action: drop
        regex: '^$'
        source_labels:
        - __service__
      - action: replace
        replacement: '$1'
        separator: /
        source_labels:
        - __meta_kubernetes_namespace
        - __service__
        target_label: job
      - action: replace
        source_labels:
        - __meta_kubernetes_namespace
        target_label: namespace
      - action: replace
        source_labels:
        - __meta_kubernetes_pod_name
        target_label: instance
      - action: replace
        source_labels:
        - __meta_kubernetes_pod_container_name
        target_label: container_name
      - replacement: '/var/log/pods/*$1/*.log'
        separator: /
        source_labels:
        - __meta_kubernetes_pod_uid
        - __meta_kubernetes_pod_container_name
        target_label: __path__
    - job_name: kubernetes-pods-indirect-controller
      kubernetes_sd_configs:
      - role: pod
      pipeline_stages: []
      relabel_configs:
      - action: drop
        regex: '.+'
        separator: ''
        source_labels:
        - __meta_kubernetes_pod_label_name
        - __meta_kubernetes_pod_label_app
      - action: keep
        regex: '^([0-9a-z-.]+)(-[0-9a-f]{8,10})$'
        source_labels:
        - __meta_kubernetes_pod_controller_name
      - action: replace
        regex: '^([0-9a-z-.]+)(-[0-9a-f]{8,10})$'
        source_labels:
        - __meta_kubernetes_pod_controller_name
        target_label: __service__
      - source_labels:
        - __meta_kubernetes_pod_node_name
        target_label: __host__
      - action: drop
        regex: '^$'
        source_labels:
        - __service__
      - action: replace
        replacement: '$1'
        separator: '/'
        source_labels:
        - __meta_kubernetes_namespace
        - __service__
        target_label: job
      - action: replace
        source_labels:
        - __meta_kubernetes_namespace
        target_label: namespace
      - action: replace
        source_labels:
        - __meta_kubernetes_pod_name
        target_label: instance
      - action: replace
        source_labels:
        - __meta_kubernetes_pod_container_name
        target_label: container_name
      - replacement: '/var/log/pods/*$1/*.log'
        separator: '/'
        source_labels:
        - __meta_kubernetes_pod_uid
        - __meta_kubernetes_pod_container_name
        target_label: __path__
    - job_name: kubernetes-pods-static
      kubernetes_sd_configs:
      - role: pod
      pipeline_stages: []
      relabel_configs:
      - action: drop
        regex: '^$'
        source_labels:
        - __meta_kubernetes_pod_annotation_kubernetes_io_config_mirror
      - action: replace
        source_labels:
        - __meta_kubernetes_pod_label_component
        target_label: __service__
      - source_labels:
        - __meta_kubernetes_pod_node_name
        target_label: __host__
      - action: drop
        regex: '^$'
        source_labels:
        - __service__
      - action: replace
        replacement: '$1'
        separator: '/'
        source_labels:
        - __meta_kubernetes_namespace
        - __service__
        target_label: job
      - action: replace
        source_labels:
        - __meta_kubernetes_namespace
        target_label: namespace
      - action: replace
        source_labels:
        - __meta_kubernetes_pod_name
        target_label: instance
      - action: replace
        source_labels:
        - __meta_kubernetes_pod_container_name
        target_label: container_name
      - replacement: '/var/log/pods/*$1/*.log'
        separator: '/'
        source_labels:
        - __meta_kubernetes_pod_annotation_kubernetes_io_config_mirror
        - __meta_kubernetes_pod_container_name
        target_label: __path__
---
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: promtail
  namespace: CLUSTER-monitoring
spec:
  selector:
    matchLabels:
      name: promtail
  template:
    metadata:
      labels:
        name: promtail
    spec:
      containers:
        - name: promtail
          image: grafana/promtail:2.2.1
          args:
          - '-config.file=/etc/promtail/promtail.yaml'
          env:
          - name: HOSTNAME
            valueFrom:
              fieldRef:
                fieldPath: spec.nodeName
          readinessProbe:
            httpGet:
              path: /ready
              port: http
              scheme: HTTP
            initialDelaySeconds: 10
          ports:
            - name: http
              containerPort: 80
          securityContext:
            privileged: true
            runAsUser: 0
          volumeMounts:
          - name: config
            mountPath: /etc/promtail
          - name: logs-docker
            mountPath: /var/lib/docker/containers
            readOnly: true
          - name: logs-varlog
            mountPath: /var/log
      volumes:
      - name: config
        configMap:
          name: promtail-config
      - name: logs-varlog
        hostPath:
          path: /var/log
      - name: logs-docker
        hostPath:
          path: /var/lib/docker/containers
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: loki-config
  namespace: CLUSTER-monitoring
data:
  # TODO: split this apart a bit (defaults to all features enabled). Need to split compactor, at least,
  # since it's supposed to be a singleton
  loki.yaml: |-
    auth_enabled: false

    server:
      http_listen_port: 3100
      grpc_listen_port: 9096

    ingester:
      wal:
        enabled: true
        dir: /tmp/wal
      lifecycler:
        address: 127.0.0.1
        ring:
          kvstore:
            store: inmemory
          replication_factor: 1
        final_sleep: 0s
      # N.B. as for prometheus & thanos, these are artifically low for demo purposes
      chunk_idle_period: 10m
      max_chunk_age: 10m
      chunk_target_size: 1048576
      chunk_retain_period: 30s
      max_transfer_retries: 0

    schema_config:
      configs:
        - from: 2000-01-01
          store: boltdb-shipper
          object_store: gcs
          schema: v11
          index:
            prefix: index_
            period: 24h

    storage_config:
      boltdb_shipper:
        active_index_directory: /tmp/loki/index
        shared_store: gcs
        cache_location: /tmp/loki/boltdb-cache
      gcs:
        bucket_name: kjames-loki

    compactor:
      working_directory: /tmp/loki/compactor
      shared_store: filesystem
      compaction_interval: 5m

    limits_config:
      reject_old_samples: true
      reject_old_samples_max_age: 168h

    chunk_store_config:
      max_look_back_period: 0s

    table_manager:
      retention_deletes_enabled: false
      retention_period: 0s

    ruler:
      storage:
        type: local
        local:
          directory: /tmp/loki/rules
      rule_path: /tmp/loki/rules-temp
      alertmanager_url: http://alertmanager.CLUSTER-monitoring.svc:9093
      ring:
        kvstore:
          store: inmemory
      enable_api: true
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: loki
  namespace: CLUSTER-monitoring
spec:
  replicas: 2
  selector:
    matchLabels:
      name: loki
  template:
    metadata:
      labels:
        name: loki
    spec:
      containers:
        - name: loki
          image: grafana/loki:2.2.1
          args:
          - '-config.file=/etc/loki/loki.yaml'
          env:
            - name: GOOGLE_APPLICATION_CREDENTIALS
              value: /etc/secret/adc.json
          ports:
            - name: http
              containerPort: 3100
            - name: grpc
              containerPort: 9096
          # TODO: liveness and readiness probes
          volumeMounts:
            # TODO: pvc for ingestor storage
            - name: config
              mountPath: /etc/loki
            - name: thanos-gcs-creds
              mountPath: /etc/secret
              readOnly: false
      volumes:
        - name: config
          configMap:
            name: loki-config
        - name: thanos-gcs-creds  # TODO: rename
          secret:
            secretName: thanos-gcs-creds
---
apiVersion: v1
kind: Service
metadata:
  name: loki
  namespace: CLUSTER-monitoring
spec:
  selector:
    name: loki
  ports:
    - protocol: TCP
      port: 3100
      targetPort: 3100
  clusterIP: None
  type: ClusterIP
